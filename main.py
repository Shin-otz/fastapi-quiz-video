import subprocess
from fastapi import FastAPI, HTTPException, Query
from fastapi.responses import FileResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
import uvicorn
import ffmpeg
import requests
from pathlib import Path
import re
import mimetypes
import os
import logging
from mutagen.mp3 import MP3
from typing import List
import subprocess
import shutil
import time
import traceback
from moviepy import AudioFileClip, CompositeAudioClip, ImageClip, TextClip, CompositeVideoClip,ColorClip
import moviepy
import numpy as np
from PIL import Image, ImageDraw, ImageFont
from moviepy.video.fx.FadeIn import FadeIn
from moviepy.video.fx.FadeOut import FadeOut
from moviepy.video.fx.CrossFadeIn import CrossFadeIn
import sys
from typing import Dict, Any
import uuid, os

from urllib.parse import urlparse

from fastapi import Body
from typing import Any

# uvicornê³¼ ê°™ì€ í•¸ë“¤ëŸ¬ ì‚¬ìš©
logging.basicConfig(
    level=logging.DEBUG,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    stream=sys.stdout  # <- ê¼­ stdoutìœ¼ë¡œ ì§€ì •
)

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

app = FastAPI()

logger.debug("HAHa ...")
logger.debug(subprocess.check_output(["ffmpeg", "-version"]).decode())
# tmp í´ë” ìƒì„±
Path("tmp").mkdir(parents=True, exist_ok=True)

app = FastAPI()
app.mount("/static", StaticFiles(directory="tmp"), name="static")


# ê¸°ì¡´ ì˜ìƒ ìƒì„± í•¨ìˆ˜ëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©

def apply_mapping_to_format(entry: dict) -> dict:
    """
    entry: metadata + format í¬í•¨ëœ dict
    í•´ë‹¹ entryì˜ 'format' ë‚´ë¶€ì˜ layersì— ëŒ€í•´ í•„ìš”í•œ ê°’ì„ ì±„ì›Œë„£ìŒ
    """
    mapping_data = entry.copy()
    format_data = mapping_data.get("format", {})
    layers = format_data.get("layers", [])

    for layer in layers:
        name = layer.get("name")
        layer_type = layer.get("type")

        if name in mapping_data:
            value = mapping_data[name]
            if layer_type == "image":
                layer["imgUrl"] = value
            elif layer_type == "text":
                layer["text"] = value
            elif layer_type == "audio":
                layer["audioUrl"] = value

    return format_data

# ì—”ë“œí¬ì¸íŠ¸: ë¹„ë””ì˜¤ ìƒì„± ì—†ì´ ë§¤í•‘ëœ í¬ë§·ë§Œ ë°˜í™˜
@app.post("/generate-from-layers")
async def generate_from_layers(entries: List[Dict[str, Any]] = Body(...)):
    results = []
    for entry in entries:
        updated_format = apply_mapping_to_format(entry)
        results.append({
            "status": "ok",
            "mappedFormat": updated_format
        })
    return results

# Step 1. ë¯¸ë””ì–´ ì‚¬ì „ ë‹¤ìš´ë¡œë“œ ë° ê¸¸ì´ ê³„ì‚°
def preprocess_layers(
    layers: List[dict],
    download_cache: dict = None,
    used_files: set = None
) -> List[dict]:
    print("LAYER ***********")
    print(layers)

    if used_files is None:
        used_files = set()
    if download_cache is None:
        download_cache = {}

    for layer in layers:
        t = layer.get("type")
        layer["__duration"] = None
        layer["__actual_path"] = None

        if t == "audio":
            audio_url = layer.get("audioUrl", "")
            print("ğŸ” [AUDIO] ì›ë³¸ URL:", audio_url)
            path = download_if_remote(audio_url, cache=download_cache, used_files=used_files)
            print("ğŸ“¥ ë‹¤ìš´ë¡œë“œëœ ì˜¤ë””ì˜¤ ê²½ë¡œ:", path)

            if path and Path(path).exists():
                try:
                    layer["__actual_path"] = path
                    audio_dur = get_duration(path)
                    layer["__duration"] = (
                        float(layer.get("gapBefore", 0)) +
                        audio_dur +
                        float(layer.get("gapAfter", 0))
                    )
                    print(f"âœ… ì˜¤ë””ì˜¤ duration: {layer['__duration']}ì´ˆ")
                except Exception as e:
                    print("âŒ ì˜¤ë””ì˜¤ duration ê³„ì‚° ì‹¤íŒ¨:", e)

        elif t == "text":
            mp3_url = layer.get("mp3Url", "")
            print("ğŸ” [TEXT] mp3 URL:", mp3_url)

            if mp3_url:
                path = download_if_remote(mp3_url, cache=download_cache, used_files=used_files)
                print("ğŸ“¥ ë‹¤ìš´ë¡œë“œëœ mp3 ê²½ë¡œ:", path)

                if path and Path(path).exists():
                    try:
                        layer["__actual_path"] = path
                        mp3_dur = get_duration(path)
                        layer["__duration"] = (
                            float(layer.get("mp3PreGap", 0)) +
                            mp3_dur +
                            float(layer.get("mp3PostGap", 0))
                        )
                        print(f"âœ… í…ìŠ¤íŠ¸ mp3 duration: {layer['__duration']}ì´ˆ")
                    except Exception as e:
                        print("âŒ í…ìŠ¤íŠ¸ mp3 duration ê³„ì‚° ì‹¤íŒ¨:", e)

        elif t == "countdown":
            layer["__duration"] = float(layer.get("countdownStart", 5))
            print(f"â± ì¹´ìš´íŠ¸ë‹¤ìš´ duration: {layer['__duration']}ì´ˆ")

        elif "duration" in layer:
            layer["__duration"] = float(layer.get("duration", 0))
            print(f"ğŸ“¦ ê¸°ë³¸ duration ì§€ì •: {layer['__duration']}ì´ˆ")

    return layers


# Step 2. ë¶€ë¶„ ë ˆì´ì–´ ì‹œê°„ ì •ë¦¬
def calculate_partial_timings(layers: List[dict], default_duration=3.0) -> None:
    layer_map = {l["id"]: l for l in layers}
    cursor = 0

    for layer in layers:
        if layer.get("timeMode") != "ë¶€ë¶„":
            continue

        start = cursor + float(layer.get("gapBefore", 0))

        if layer.get("linkMode") == "relative" and layer.get("linkedLayerId"):
            ref = layer_map.get(layer["linkedLayerId"])
            if ref:
                anchor = ref["endTime"] if layer["relativeAnchor"] == "end" else ref["startTime"]
                start = float(anchor or 0) + float(layer.get("offset", 0))

        dur = float(layer.get("__duration") or layer.get("duration", default_duration))
        layer["startTime"] = round(start, 1)
        layer["endTime"] = round(start + dur, 1)
        layer["duration"] = round(dur, 1)

        cursor = layer["endTime"] + float(layer.get("gapAfter", 0))

# Step 3. ì´ë¯¸ì§€ ë ˆì´ì–´ ì‹œê°„ ì—°ë™ ì²˜ë¦¬
def resolve_image_timings(layers: List[dict]) -> None:
    layer_map = {l["id"]: l for l in layers}

    for layer in layers:
        if layer["type"] == "image" and layer.get("timeMode") == "ë¶€ë¶„":
            s = layer_map.get(layer.get("linkedStartLayerId"))
            e = layer_map.get(layer.get("linkedEndLayerId"))
            if s and e:
                layer["startTime"] = round(s["startTime"], 1)
                layer["endTime"] = round(e["endTime"], 1)
                layer["duration"] = round(layer["endTime"] - layer["startTime"], 1)

# Step 4. ì „ì²´ duration ê³„ì‚°
def calculate_total_duration(layers: List[dict]) -> float:
    valid = [float(l["endTime"]) for l in layers if "endTime" in l]
    if not valid:
        return 0.0
    return max(valid)

# Step 5. full ì²˜ë¦¬
def apply_full_end_link(layers: List[dict], total_duration: float) -> None:
    for layer in layers:
        if layer.get("endLinkMode") == "full":
            offset = float(layer.get("endOffset", 0))
            layer["endTime"] = round(total_duration + offset, 1)
            layer["duration"] = round(layer["endTime"] - layer["startTime"], 1)

#Step 6. ì „ì²´ timeMode ì²˜ë¦¬
def apply_full_duration_to_all(layers: List[dict], total_duration: float) -> None:
    for layer in layers:
        if layer.get("timeMode") == "ì „ì²´":
            layer["startTime"] = 0
            layer["endTime"] = total_duration
            layer["duration"] = total_duration

@app.post("/debug-timings")
async def debug_layer_timings(payload: List[Dict[str, Any]]):
    print("ğŸ“¦ Payload ì „ì²´:", payload)

    if not payload or "mappedFormat" not in payload[0]:
        return {"error": "âŒ ì˜ëª»ëœ payload í˜•ì‹"}

    mapped = payload[0]["mappedFormat"]
    layers = mapped.get("layers", [])

    print("ğŸ”¢ ë ˆì´ì–´ ìˆ˜:", len(layers))
    for layer in layers:
        print(f"ğŸ§± ID: {layer.get('id')}, Type: {layer.get('type')}, Duration: {layer.get('duration')}")

    # ì—¬ê¸°ì„œ íƒ€ì´ë° ê³„ì‚° ì‹¤í–‰
    updated_layers = recalculate_all_timings(layers)
    total_duration = calculate_total_duration(updated_layers)

    return {
        "totalDuration": total_duration,
        "layers": updated_layers
    }

@app.post("/generate-video-from-layer")
async def generate_video_from_layer(entries: List[Dict[str, Any]] = Body(...)):
    """
    n8nìœ¼ë¡œë¶€í„° ì „ë‹¬ë°›ì€ JSONì„ ê¸°ë°˜ìœ¼ë¡œ ì˜ìƒ ìƒì„± + ì„ì‹œ íŒŒì¼ ì •ë¦¬ í¬í•¨
    """
    results = []
    used_files = set()
    download_cache = {}

    for entry in entries:
        try:
            print("\nğŸš€ [START] ì˜ìƒ ìƒì„± ì‹œì‘")

            mapped = entry["mappedFormat"]
            layers = mapped["layers"]

            # ì „ì²´ íƒ€ì´ë° ê³„ì‚°
            layers = recalculate_all_timings(
                layers,
                download_cache=download_cache,
                used_files=used_files
            )
            mapped["layers"] = layers


            # ğŸ¬ íŒŒì¼ëª… (UUID ê¸°ë°˜ ì‹¤ì œ ì €ì¥ìš©)
            filename = f"video_{uuid.uuid4().hex[:6]}.mp4"
            output_path = os.path.join("tmp", filename)

            # ğŸ¯ video_output_fn (question mp3 ê¸°ë°˜ ID ì‚¬ìš©)
            question_url = entry.get("question_mp3") or entry.get("questionUrl", "")
            file_id = extract_drive_id_safe(question_url)
            video_output_fn = f"video_{file_id}.mp4" if file_id else ""

            # ì˜ìƒ ìƒì„±
            result_path = make_video_from_layers(
                mapped,
                output_path,
                download_cache=download_cache,
                used_files=used_files
            )

            # ê²°ê³¼ ì¶”ê°€
            results.append({
                "status": "success",
                "videoPath": result_path,
                "filename": filename,                  # ì‹¤ì œ ì €ì¥ëœ ëœë¤ íŒŒì¼ëª…
                "video_output_fn": video_output_fn,    # ë…¼ë¦¬ì  ID ê¸°ë°˜ ì´ë¦„
                "duration": max(float(l.get("endTime", 0)) for l in layers),
            })

        except Exception as e:
            print(f"âŒ ì˜ìƒ ìƒì„± ì‹¤íŒ¨: {e}")
            results.append({
                "status": "error",
                "message": str(e)
            })

    # ğŸ”¥ ì‚¬ìš©ëœ ì„ì‹œ íŒŒì¼ ì‚­ì œ
    print("\nğŸ§¹ ì‚¬ìš©ëœ ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹œì‘")
    for path in used_files:
        try:
            f = Path(path)
            if f.exists():
                f.unlink()
                print(f"ğŸ—‘ï¸ ì‚­ì œ ì™„ë£Œ: {f}")
        except Exception as e:
            print(f"âš ï¸ ì‚­ì œ ì‹¤íŒ¨: {path} â†’ {e}")

    return results


def make_video_from_layers(
    mapped_format: Dict[str, Any],
    output_path: str,
    download_cache: dict = None,
    used_files: set = None
) -> str:
    layers_data = mapped_format["layers"]
    canvas_ratio = mapped_format.get("canvasRatio", "1024x768")
    canvas_width, canvas_height = map(int, canvas_ratio.split("x"))
    total_duration = max(float(l.get("endTime", 0)) for l in layers_data)
    base_clip = ColorClip((canvas_width, canvas_height), color=(255, 255, 255)).with_duration(total_duration)

    video_clips = []
    audio_clips = []

    if download_cache is None:
        download_cache = {}
    if used_files is None:
        used_files = set()

    font_path = os.path.abspath("tmp/NanumMyeongjo-YetHangul.ttf")
    if not os.path.exists(font_path):
        raise FileNotFoundError(f"âŒ í°íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {font_path}")

    for layer in layers_data:
        t = layer.get("type")
        start = float(layer.get("startTime", 0))
        dur = float(layer.get("duration", 0))
        x = int(layer.get("x", 0))
        y = int(layer.get("y", 0))
        w = int(layer.get("width", 100))
        h = int(layer.get("height", 50))
        opacity = float(layer.get("backgroundOpacity", 1))

        if t == "image":
            img_url = layer.get("imgUrl")
            img_path = download_if_remote(img_url, cache=download_cache, used_files=used_files)
            if img_path and os.path.exists(img_path):
                try:
                    clip = (ImageClip(img_path)
                            .resized(width=w)
                            .with_opacity(opacity)
                            .with_start(start)
                            .with_duration(dur)
                            .with_position((x, y)))
                    video_clips.append(clip)
                except Exception as e:
                    print("âŒ ì´ë¯¸ì§€ í´ë¦½ ìƒì„± ì‹¤íŒ¨:", e)


        elif t == "text":
            txt = layer.get("text", "")
            font_size = int(layer.get("fontSize", 30))
            color = layer.get("color", "black")
            align = layer.get("textAlign", "left")
            vertical_align = layer.get("verticalAlign", "top")
            line_height = float(layer.get("lineHeight", 1.0))
            wrapped = wrap_text_by_width(txt, font_path, font_size, max_width=w)
            img = draw_text_with_spacing(
                wrapped,
                font_path,
                font_size,
                color,
                (w, h),
                spacing=line_height,
                align=align,
                vertical_align=vertical_align
            )
            clip = (ImageClip(np.array(img))
                    .with_start(start)
                    .with_duration(dur)
                    .with_position((x, y)))
            video_clips.append(clip)

        elif t == "countdown":
            count = int(layer.get("countdownStart", 5))
            font_size = int(layer.get("fontSize", 50))
            color = layer.get("color", "red")
            for i in range(count, 0, -1):
                img = draw_text_with_spacing(str(i), font_path, font_size, color, (w, h), spacing=1, align='center')
                tclip = (ImageClip(np.array(img))
                         .with_start(start + (count - i))
                         .with_duration(1)
                         .with_position((x, y)))
                video_clips.append(tclip)
            beep_path = f"tmp/beep_{uuid.uuid4().hex[:6]}.mp3"
            generate_beep_sequence(count, beep_path)
            audio_clips.append(AudioFileClip(beep_path).with_start(start))
            used_files.add(beep_path)

        elif t == "audio":
            audio_url = layer.get("audioUrl", "").strip()
            audio_path = download_if_remote(audio_url, cache=download_cache, used_files=used_files)
            if audio_path and os.path.exists(audio_path):
                aclip = AudioFileClip(audio_path).with_start(start)
                audio_clips.append(aclip)

    final_audio = CompositeAudioClip(audio_clips) if audio_clips else None
    final_video = CompositeVideoClip([base_clip] + video_clips).with_audio(final_audio)
    output_path = os.path.abspath(output_path)
    final_video.write_videofile(output_path, fps=25, codec='libx264', audio_codec='aac')

    final_video.close()
    if final_audio:
        final_audio.close()

    return output_path



def check_ffmpeg_drawtext():
    try:
        # ffmpeg í•„í„° ëª©ë¡ì—ì„œ drawtextê°€ ìˆëŠ”ì§€ í™•ì¸
        result = subprocess.run(
            ["ffmpeg", "-filters"],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        filters_output = result.stdout

        if "drawtext" in filters_output:
            logger.info("âœ… ffmpeg drawtext í•„í„° ì§€ì› í™•ì¸ë¨.")
        else:
            logger.error("âŒ ffmpeg drawtext í•„í„°ê°€ ì—†ìŠµë‹ˆë‹¤! Dockerfileì„ ìˆ˜ì •í•˜ê±°ë‚˜ ë¹Œë“œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    except FileNotFoundError:
        logger.error("âŒ ffmpeg ëª…ë ¹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ffmpegê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    except Exception as e:
        logger.exception(f"âŒ ffmpeg í•„í„° í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

def generate_beep_sequence(beep_seconds: int, output_path: str):
    from pydub import AudioSegment
    from pydub.generators import Sine

    beep = Sine(1000).to_audio_segment(duration=300).apply_gain(-3)   # 0.3ì´ˆ ì‚
    silence = AudioSegment.silent(duration=700)                       # 0.7ì´ˆ ì‰¼
    one_beep = beep + silence
    countdown_beep = one_beep * beep_seconds
    countdown_beep.export(output_path, format="mp3")
    return output_path

def recalculate_all_timings(
    layers: List[dict],
    default_duration: float = 3.0,
    download_cache: dict = None,
    used_files: set = None
) -> List[dict]:
    """
    ì „ì²´ íƒ€ì´ë° ê³„ì‚° íŒŒì´í”„ë¼ì¸ (preprocess â†’ timings â†’ total duration â†’ full ì²˜ë¦¬)
    """
    if download_cache is None:
        download_cache = {}
    if used_files is None:
        used_files = set()

    print("\nğŸ” [STEP 1] ë¯¸ë””ì–´ ì‚¬ì „ ë‹¤ìš´ë¡œë“œ ë° ê¸¸ì´ ê³„ì‚°")
    layers = preprocess_layers(layers, download_cache=download_cache, used_files=used_files)

    print("\nğŸ§® [STEP 2] 'ë¶€ë¶„' ë ˆì´ì–´ ì‹œê°„ ì •ë¦¬")
    calculate_partial_timings(layers, default_duration)

    print("\nğŸ–¼ï¸ [STEP 3] ì´ë¯¸ì§€ ë ˆì´ì–´ ì‹œê°„ ì—°ë™")
    resolve_image_timings(layers)

    print("\nâ±ï¸ [STEP 4] ì „ì²´ ì˜ìƒ ì´ ì‹œê°„ ê³„ì‚°")
    total_duration = calculate_total_duration(layers)
    print(f"ğŸ“ ì „ì²´ ì˜ìƒ ê¸¸ì´: {total_duration:.1f}ì´ˆ")

    print("\nğŸ” [STEP 5] endLinkMode = full ì²˜ë¦¬")
    apply_full_end_link(layers, total_duration)

    print("\nğŸŒ [STEP 6] timeMode = ì „ì²´ ì²˜ë¦¬")
    apply_full_duration_to_all(layers, total_duration)

    print("\nâœ… [RESULT] ë ˆì´ì–´ë³„ íƒ€ì´ë° ì •ë³´")
    for i, l in enumerate(layers):
        print(f"{i+1:2}. ğŸ§© {l.get('type','?')} | {l.get('name','(no-name)'):<15} "
              f"â†’ â± {l.get('startTime', '?')} ~ {l.get('endTime', '?')}  "
              f"(dur: {l.get('duration', '?')})")

    return layers


def recalculate_layer_timings_for_backend(layers: List[dict], default_duration: float = 3.0) -> List[dict]:
    """
    Reactì—ì„œ ì‚¬ìš©í•œ ì‹œê°„ ì •ë ¬ ë¡œì§ì„ Pythonìœ¼ë¡œ í¬íŒ…í•œ ë²„ì „.
    """
    round1 = lambda v: round(v, 1)
    new_layers = [l.copy() for l in layers]
    layer_map = {l["id"]: l for l in new_layers}

    cursor = 0
    for layer in new_layers:
        if layer["type"] in {"text", "countdown", "audio"} and layer["timeMode"] == "ë¶€ë¶„":
            base_start = cursor + float(layer.get("gapBefore", 0))

            if layer.get("linkMode") == "relative" and layer.get("linkedLayerId"):
                base = layer_map.get(layer["linkedLayerId"])
                if base:
                    anchor = base["endTime"] if layer.get("relativeAnchor") == "end" else base["startTime"]
                    base_start = float(anchor or 0) + float(layer.get("offset", 0))

            dur = float(layer.get("duration") or default_duration)

            if layer["type"] == "text" and layer.get("mp3Url", "").strip():
                dur = (
                    float(layer.get("mp3PreGap", 0)) +
                    float(layer.get("duration", default_duration)) +
                    float(layer.get("mp3PostGap", 0))
                )

            layer["startTime"] = round1(base_start)
            layer["endTime"] = round1(base_start + dur)
            layer["duration"] = round1(layer["endTime"] - layer["startTime"])
            cursor = layer["endTime"] + float(layer.get("gapAfter", 0))

    for layer in new_layers:
        if layer["type"] == "image" and layer["timeMode"] == "ë¶€ë¶„":
            s = layer_map.get(layer.get("linkedStartLayerId"))
            e = layer_map.get(layer.get("linkedEndLayerId"))
            if s and e:
                layer["startTime"] = round1(s["startTime"])
                layer["endTime"] = round1(e["endTime"])
                layer["duration"] = round1(layer["endTime"] - layer["startTime"])

    total_duration = max(float(l.get("endTime", 0)) for l in new_layers)

    for layer in new_layers:
        if layer.get("endLinkMode") == "full":
            layer["endTime"] = round1(total_duration + float(layer.get("endOffset", 0)))
            layer["duration"] = round1(layer["endTime"] - layer["startTime"])  # âœ… ì´ê±¸ë¡œ ë³€ê²½

    for layer in new_layers:
        if layer["timeMode"] == "ì „ì²´":
            layer["startTime"] = 0
            layer["endTime"] = total_duration
            layer["duration"] = total_duration

    return new_layers



def draw_text_with_spacing(
    text: str,
    font_path: str,
    font_size: int,
    color: str,
    size: tuple,
    spacing: float = 1.0,
    align: str = "left",
    vertical_align: str = "top"
):
    width, height = size
    font = ImageFont.truetype(font_path, font_size)
    lines = text.split("\n")

    line_height = int(font_size * spacing)
    total_text_height = line_height * len(lines)

    # ìˆ˜ì§ ì •ë ¬
    if vertical_align in ("center", "middle"):
        y = (height - total_text_height) // 2
    elif vertical_align == "bottom":
        y = height - total_text_height
    else:
        y = 0  # top

    img = Image.new("RGBA", (width, height), (255, 255, 255, 0))
    draw = ImageDraw.Draw(img)

    for line in lines:
        line_width = draw.textlength(line, font=font)
        if align == "center":
            x = (width - line_width) // 2
        elif align == "right":
            x = width - line_width
        else:
            x = 0

        draw.text((x, y), line, font=font, fill=color)
        y += line_height

    return img



def wrap_text(text, max_chars=28):
    """
    ì…ë ¥ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ê°•ì œë¡œ ì¤„ë°”ê¿ˆ(\n) ì¶”ê°€
    ê¸°ë³¸ê°’: 18ê¸€ì ë„˜ìœ¼ë©´ ì¤„ë°”ê¿ˆ (ëŒ€ëµ ê°€ë¡œ 30%)
    """
    words = text.strip().split()
    lines = []
    current = ""

    for word in words:
        if len(current + " " + word) <= max_chars:
            current += " " + word if current else word
        else:
            lines.append(current)
            current = word
    if current:
        lines.append(current)

    return '\n'.join(lines)

def wrap_text_by_width(text, font_path, font_size, max_width):
    """
    ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ font ê¸°ì¤€ max_width ì•ˆì— ë§ê²Œ ì¤„ë°”ê¿ˆ ì²˜ë¦¬
    """
    font = ImageFont.truetype(font_path, font_size)
    dummy_img = Image.new("RGB", (10, 10))
    draw = ImageDraw.Draw(dummy_img)

    words = text.strip().split()
    lines = []
    current = ""

    for word in words:
        test_line = f"{current} {word}".strip()
        width = draw.textlength(test_line, font=font)
        if width <= max_width:
            current = test_line
        else:
            if current:
                lines.append(current)
            current = word
    if current:
        lines.append(current)

    return '\n'.join(lines)


class QuestionItem(BaseModel):
    question_type: str
    topic: str
    key_term: str
    question: str
    hint: str
    answer: str
    explanation: str
    background_url: str
    image_url: str
    question_url: str
    answer_url: str
    explanation_url: str


class FileRequest(BaseModel):
    filename: str


def check_ffmpeg_installed():
    try:
        result = subprocess.run(
            ["ffmpeg", "-version"],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            check=True
        )
        logger.info("âœ… FFmpeg ì„¤ì¹˜  í™•ì¸ë¨.")
    except FileNotFoundError:
        logger.error("âŒ FFmpegê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        raise RuntimeError("FFmpegê°€ ì‹œìŠ¤í…œì— ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. apt ë˜ëŠ” brewë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
    except subprocess.CalledProcessError as e:
        logger.error("âŒ FFmpeg ì‹¤í–‰ ì‹¤íŒ¨:")
        logger.error(e.stderr.decode())
        raise RuntimeError("FFmpegê°€ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")


def extract_drive_id(url: str) -> str:
    match = re.search(r"/d/([a-zA-Z0-9_-]+)", url)
    if match:
        return match.group(1)
    return str(uuid.uuid4())[:8]
def extract_drive_id_safe(url: str) -> str:
    if not url or not isinstance(url, str):
        return str(uuid.uuid4())[:8]  # fallback for None or non-str
    match = re.search(r"/d/([a-zA-Z0-9_-]+)", url)
    if match:
        return match.group(1)
    return str(uuid.uuid4())[:8]

def convert_drive_url(url: str) -> str:
    # Google Drive ë³´ê¸° ë§í¬ â†’ ì§ì ‘ ë‹¤ìš´ë¡œë“œ ë§í¬ ë³€í™˜
    match = re.search(r"/d/([a-zA-Z0-9_-]+)", url)
    if not match:
        return url  # ë³€í™˜ ì‹¤íŒ¨í•˜ë©´ ì›ë³¸ ë°˜í™˜
    file_id = match.group(1)
    return f"https://drive.google.com/uc?export=download&id={file_id}"
def download_if_remote(
    url: str,
    cache: dict = None,
    used_files: set = None
) -> str:
    if not url:
        return ""

    # Google Drive ë³€í™˜
    if "drive.google.com" in url:
        url = convert_drive_url(url)

    if cache is not None and url in cache:
        print(f"â™»ï¸ [HIT] ìºì‹œ ì¬ì‚¬ìš©: {url} â†’ {cache[url]}")
        return cache[url]

    # íŒŒì¼ í™•ì¥ì ì¶”ì¶œ
    ext = os.path.splitext(urlparse(url).path)[-1]
    if not ext or len(ext) > 6:
        ext = ".bin"

    # Google Drive IDë¥¼ íŒŒì¼ëª…ìœ¼ë¡œ
    unique_name = extract_drive_id(url) or uuid.uuid4().hex[:6]
    local_path = f"tmp/{unique_name}{ext}"

    # ì´ë¯¸ ì¡´ì¬í•˜ë©´ ì¬ì‚¬ìš©
    if Path(local_path).exists():
        print(f"â™»ï¸ [HIT] íŒŒì¼ ì¡´ì¬ ì¬ì‚¬ìš©: {local_path}")
        if cache is not None:
            cache[url] = local_path
        if used_files is not None:
            used_files.add(local_path)
        return local_path

    try:
        print(f"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {url}")
        with requests.get(url, stream=True) as r:
            r.raise_for_status()
            with open(local_path, 'wb') as f:
                for chunk in r.iter_content(chunk_size=8192):
                    f.write(chunk)
        print(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {local_path}")

        if cache is not None:
            cache[url] = local_path
        if used_files is not None:
            used_files.add(local_path)

        return local_path

    except Exception as e:
        print(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {url} â†’ {e}")
        return ""


def make_video_from_mapped_format(payload: List[Dict[str, Any]], output_path: str):
    entry = payload[0]  # ì²« ë²ˆì§¸ í•­ëª©ë§Œ ì²˜ë¦¬
    format_data = entry["mappedFormat"]
    canvas_w, canvas_h = map(int, format_data.get("canvasRatio", "1280x720").split("x"))
    layers = format_data.get("layers", [])

    base = ColorClip((canvas_w, canvas_h), color=(255,255,255))
    total_duration = max(float(l.get("endTime", 0)) for l in layers)
    base = base.with_duration(total_duration)

    video_clips = []
    audio_clips = []

    for layer in layers:
        typ = layer.get("type")
        start = float(layer.get("startTime", 0))
        duration = float(layer.get("duration", 0))
        x, y = int(layer.get("x", 0)), int(layer.get("y", 0))
        w, h = int(layer.get("width", 100)), int(layer.get("height", 50))
        opacity = float(layer.get("backgroundOpacity", 1))

        if typ == "image":
            img_path = download_if_remote(layer.get("imgUrl", ""))
            if img_path:
                clip = (ImageClip(img_path)
                        .resized(width=w)
                        .with_opacity(opacity)
                        .with_start(start)
                        .with_duration(duration)
                        .with_position((x, y)))
                video_clips.append(clip)

        elif typ == "text":
            txt = layer.get("text", "")
            fontsize = int(layer.get("fontSize", 30))
            color = layer.get("color", "#000000")
            clip = (TextClip(txt, fontsize=fontsize, color=color, size=(w,h), method='caption')
                    .with_start(start)
                    .with_duration(duration)
                    .with_position((x, y)))
            video_clips.append(clip)

        elif typ == "audio":
            audio_path = download_if_remote(layer.get("audioUrl", ""))
            if audio_path:
                acl = AudioFileClip(audio_path).with_start(start)
                audio_clips.append(acl)

    final_audio = CompositeAudioClip(audio_clips) if audio_clips else None
    final_video = CompositeVideoClip([base] + video_clips).with_audio(final_audio)
    output_path = os.path.abspath(output_path)
    final_video.write_videofile(output_path, fps=25, codec="libx264", audio_codec="aac")

    # Clean up
    for l in layers:
        if "imgUrl" in l:
            p = Path(l["imgUrl"])
            if str(p).startswith("tmp/") and p.exists():
                p.unlink()

    return output_path

def download_file(url: str, filename: str) -> str:
    if "drive.google.com" in url:
        url = convert_drive_url(url)

    r = requests.get(url)
    r.raise_for_status()

    path = Path(f"tmp/{filename}")
    path.parent.mkdir(parents=True, exist_ok=True)
    if not path.exists():
        with open(path, "wb") as f:
            f.write(r.content)
    return str(path)


def download_file_tmp2(url: str, filename: str) -> str:
    if "drive.google.com" in url:
        url = convert_drive_url(url)

    r = requests.get(url)
    r.raise_for_status()

    path = Path(f"tmp2/{filename}")
    path.parent.mkdir(parents=True, exist_ok=True)
    if not path.exists():
        with open(path, "wb") as f:
            f.write(r.content)
    return str(path)


@app.get("/check-list")
def check_list(filename: str):
    file_path = Path(f"tmp/{filename}_list.txt")
    if file_path.exists():
        return FileResponse(path=str(file_path), media_type="text/plain")
    else:
        return {"error": "list.txt íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ"}


def download_drive_file(url: str, dest: Path) -> str:
    # URLì—ì„œ ID ì¶”ì¶œ
    file_id = url.split("/d/")[1].split("/")[0]
    direct_url = f"https://drive.google.com/uc?export=download&id={file_id}"
    r = requests.get(direct_url)
    dest.write_bytes(r.content)
    return str(dest)


def drive_url_to_direct_link(url: str) -> str:
    # ì˜ˆ: https://drive.google.com/file/d/1abcDEF/view?usp=sharing
    match = re.search(r"/d/([a-zA-Z0-9_-]+)", url)
    if not match:
        raise ValueError("Invalid Google Drive URL")
    file_id = match.group(1)
    return f"https://drive.google.com/uc?export=download&id={file_id}"


class VideoMergeRequest(BaseModel):
    sheet_name: str
    merged_video_name: str
    videos: List[str]  # âœ… ì¤‘ìš”: ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ì˜


def download_mp4(url: str, filename: str) -> str:
    direct_url = drive_url_to_direct_link(url)
    TMP_DIR = Path("tmp")
    path = TMP_DIR / filename
    with requests.get(direct_url, stream=True) as r:
        r.raise_for_status()
        with open(path, "wb") as f:
            for chunk in r.iter_content(chunk_size=8192):
                f.write(chunk)
    while True:
        if os.path.exists(path) and os.path.getsize(path) > 1000:
            break
    time.sleep(0.5)
    return str(path)

def merge_videos_with_fade(file_paths: list[str], output_name: str, fade_duration: float = 1.0) -> str:
    TMP_DIR = Path("tmp")
    TMP_DIR.mkdir(exist_ok=True)

    # ì²« ë²ˆì§¸ íŒŒì¼ì„ ê¸°ì¤€ìœ¼ë¡œ ì‹œì‘
    output_path = TMP_DIR / f"{output_name}.mp4"

    if len(file_paths) < 2:
        raise ValueError("ìµœì†Œ ë‘ ê°œ ì´ìƒì˜ ì˜ìƒì´ í•„ìš”í•©ë‹ˆë‹¤.")

    # ìˆœì°¨ì ìœ¼ë¡œ xfadeë¡œ í•©ì¹˜ê¸°
    current = file_paths[0]
    for idx, next_video in enumerate(file_paths[1:], start=1):
        tmp_out = TMP_DIR / f"{output_name}_step{idx}.mp4"

        # xfadeëŠ” ë‘ê°œì˜ ì…ë ¥ë§Œ ë°›ìœ¼ë¯€ë¡œ, ë°˜ë³µì ìœ¼ë¡œ ì´ì–´ ë¶™ì„
        # fade_durationë§Œí¼ êµì°¨ ì „í™˜
        command = [
            "ffmpeg",
            "-y",
            "-i", current,
            "-i", next_video,
            "-filter_complex",
            f"[0:v][1:v]xfade=transition=fade:duration={fade_duration}:offset=0[v];"
            f"[0:a][1:a]acrossfade=d={fade_duration}[a]",
            "-map", "[v]",
            "-map", "[a]",
            "-c:v", "libx264",
            "-crf", "18",
            "-preset", "veryfast",
            "-c:a", "aac",
            "-b:a", "192k",
            str(tmp_out)
        ]
        subprocess.run(command, check=True)

        # ë‹¤ìŒ ë‹¨ê³„ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©
        current = str(tmp_out)

    # ìµœì¢… ê²°ê³¼ë¬¼
    final_output = TMP_DIR / f"{output_name}_final.mp4"
    Path(current).rename(final_output)
    return str(final_output)

def get_duration(path: str) -> float:
    info = ffmpeg.probe(path)
    return float(info['format']['duration'])

def merge_videos_ffmpeg2(file_paths: list[str], output_name: str, fade_duration: float = 1.0) -> str:
    TMP_DIR = Path("tmp")
    TMP_DIR.mkdir(exist_ok=True)

    # ê²½ë¡œë¥¼ / í˜•ì‹ìœ¼ë¡œ
    file_paths = [str(Path(p).resolve().as_posix()) for p in file_paths]

    current = file_paths[0]
    for idx, next_file in enumerate(file_paths[1:], start=1):
        tmp_out = TMP_DIR / f"{output_name}_step{idx}.mp4"
        tmp_out = tmp_out.resolve().as_posix()

        dur = get_duration(current)
        offset = max(dur - fade_duration, 0)

        filter_complex = (
            f"[0:v][1:v]xfade=transition=fade:duration={fade_duration}:offset={offset}[v];"
            f"[0:a][1:a]acrossfade=d={fade_duration}[a]"
        )

        cmd = [
            "ffmpeg", "-y",
            "-i", current,
            "-i", next_file,
            "-filter_complex", filter_complex,
            "-map", "[v]", "-map", "[a]",
            "-c:v", "libx264", "-crf", "18", "-preset", "fast",
            "-c:a", "aac", "-b:a", "192k",
            tmp_out
        ]
        subprocess.run(cmd, check=True)
        current = tmp_out

    final_output = TMP_DIR / f"{output_name}_final.mp4"
    Path(current).rename(final_output)
    return str(final_output)

def merge_videos_ffmpeg(file_paths: list[str], output_name: str) -> str:
    TMP_DIR = Path("tmp")
    TMP_DIR.mkdir(exist_ok=True)

    list_path = TMP_DIR / f"{output_name}_list.txt"

    del_files = []

    # âœ… ì ˆëŒ€ê²½ë¡œ ì‚¬ìš©
    with open(list_path, "w", encoding="utf-8") as f:
        for file_path in file_paths:
            abs_path = Path(file_path).resolve().as_posix()
            f.write(f"file '{abs_path}'\n")
            del_files.append(abs_path) # ë‚˜ì¤‘ì— ì§€ìš°ê¸°

    file_num = str((len(del_files)+1)//2).zfill(2)

    output_file = f"{output_name}_{file_num}.mp4"
    output_path = TMP_DIR / f"{output_name}_{file_num}.mp4"

    del_files.append(list_path)  # ë‚˜ì¤‘ì— ì§€ìš°ê¸°
    """
    command = [
        "ffmpeg",
        "-f", "concat",
        "-safe", "0",
        "-y",
        "-i", str(list_path.resolve().as_posix()),  # ì ˆëŒ€ê²½ë¡œë¡œ ë°”ê¿”ì¤Œ
        "-c", "copy",
        str(output_path.resolve().as_posix())
    ]

    command = [
        "ffmpeg",
        "-f", "concat",
        "-safe", "0",
        "-y",
        "-i", str(list_path),
        "-c:v", "libx264",
        "-c:a", "aac",
        "-strict", "experimental",
        str(output_path)
    ]
    """
    command = [
        "ffmpeg",
        "-f", "concat",
        "-safe", "0",
        "-y",
        "-i", str(list_path),
        "-c", "copy",
        "-c:a", "aac",
        str(output_path.resolve().as_posix())
    ]

    subprocess.run(command, check=True)

    # Delete tmp folder
    for del_file in del_files:
        file_path = Path(del_file)
        if file_path.exists():
            file_path.unlink()
            print(f"âœ… íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {file_path}")
        else:
            print(f"âš  íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")

    return {"status": "ok", "output": output_file}

@app.post("/merge-videos")
async def merge_videos(payload: List[VideoMergeRequest]):
    results = []

    for item in payload:
        sheet = item.sheet_name
        merged_name = item.merged_video_name
        video_urls = item.videos

        print(f"[{sheet}] '{merged_name}' ë³‘í•© ì‹œì‘: {len(video_urls)}ê°œ ì˜ìƒ")

        # 1. ê° URLì—ì„œ mp4 ë‹¤ìš´ë¡œë“œ
        file_paths = []
        for i, url in enumerate(video_urls):
            filename = f"{merged_name}_{i}.mp4"
            try:
                path = download_mp4(url, filename)
                file_paths.append(path)
            except Exception as e:
                print(f"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {url}, ì—ëŸ¬: {e}")
                results.append({
                    "sheet": sheet,
                    "merged_video_name": merged_name,
                    "video_count": len(video_urls),
                    "status": "fail",
                    "error": str(e)
                })
                continue
        print("----")
        print(file_paths)

        # 2. FFmpegë¡œ ë³‘í•©
        try:
            print("----")
            print(file_paths)
            output_path = merge_videos_ffmpeg(file_paths, merged_name)
            status = "success"
        except Exception as e:
            print(f"ë³‘í•© ì‹¤íŒ¨: {e}")
            output_path = file_paths
            status = "fail"

        # 3. ê²°ê³¼ ì €ì¥
        results.append({
            "sheet": sheet,
            "merged_video_name": merged_name,
            "video_count": len(video_urls),
            "merged_path": output_path,
            "list_path": video_urls,
            "ffmpeg": shutil.which("ffmpeg"),
            "status": status
        })

    return {"result": results}


class NextItem(BaseModel):
    next_text_mp3_url: str
    next_bg_url: str


@app.post("/generate-mp4_next")
async def generate_next(item: NextItem):
    # ğŸ”½ ê° URLì— ëŒ€í•´ ê³ ìœ  ID ê¸°ë°˜ íŒŒì¼ëª… ìƒì„±
    next_audio_id = extract_drive_id(item.next_text_mp3_url)
    background_id = extract_drive_id(item.next_bg_url)

    # ğŸ”½ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    next_mp3_file = download_file(item.next_text_mp3_url, f"next_mp3_{next_audio_id}.mp3")
    background_image_file = download_file(item.next_bg_url, f"next_bg_{background_id}.png")

    # ğŸ”½ ì¶œë ¥ íŒŒì¼ëª…
    output_filename = f"next_{next_audio_id}.mp4"
    output_file = f"tmp/{output_filename}"

    data_ = {
        "next_mp3": next_mp3_file,
        "next_bg_image": background_image_file,
    }

    make_next_moviepy_mp4(data_, output_file)

    # create_video(data_, (output_file))

    BASE_URL = "https://primary-production-8af2.up.railway.app"
    public_video_url = f"{BASE_URL}/static/{output_filename}"

    return {
        "status": "ok",
        "next_mp3": next_mp3_file,
        "next_bg_image": background_image_file,
        "next_mp4": output_file
    }


def make_next_moviepy_mp4(data_, output_path):
    next_mp3_path = os.path.abspath(data_["next_mp3"])
    bgimage_path = os.path.abspath(data_["next_bg_image"])
    output_path = os.path.abspath(output_path)

    # ì˜¤ë””ì˜¤
    question_a = AudioFileClip(next_mp3_path)
    final_audio = CompositeAudioClip([question_a]).with_fps(44100)

    # ì´ë¯¸ì§€ (moviepy 2.1.2 ê¸°ì¤€ with_resize ì‚¬ìš©)

    base_clip = ImageClip(bgimage_path).with_duration(final_audio.duration)

    # í•©ì„±
    final_clip = base_clip.with_audio(final_audio)

    # ì¶œë ¥
    final_clip.write_videofile(
        output_path,
        fps=25,
        codec='libx264',
        audio_codec='aac'
    )
    print(f"âœ… ìƒì„± ì™„ë£Œ (moviepy): {output_path}")

    del_files = []
    del_files.append(next_mp3_path)
    del_files.append(bgimage_path)

    # Delete tmp folder
    for del_file in del_files:
        file_path = Path(del_file)
        if file_path.exists():
            file_path.unlink()
            print(f"âœ… íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {file_path}")
        else:
            print(f"âš  íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")

    return {"status": "ok", "output": output_path}


def make_next_mp4(data_, output_path):
    next_mp3_path = data_["next_mp3"]
    bgimage_path = data_["next_bg_image"]

    try:
        # ì´ë¯¸ì§€ ì…ë ¥ (ë°˜ë³µ), í”„ë ˆì„ë ˆì´íŠ¸ 1fps ì§€ì •
        image_input = ffmpeg.input(bgimage_path, loop=1)

        question_a = AudioFileClip(next_mp3_path)
        final_audio = CompositeAudioClip([question_a]).with_fps(44100)
        output_audio_path = os.path.join("tmp", f"next_final.mp3")
        final_audio.write_audiofile(output_audio_path)
        # ì˜¤ë””ì˜¤ ì…ë ¥
        audio_input = ffmpeg.input(output_audio_path)

        # ìŠ¤ì¼€ì¼ í•„í„° ì ìš©
        base = image_input.filter('scale', 1080, 720)

        ffmpeg.output(
            base, audio_input,
            output_path,

            vcodec='libx264',
            acodec='aac',
            audio_bitrate='192k',
            pix_fmt='yuv420p',
            shortest=None,
            movflags='+faststart'
        ).run(overwrite_output=True)

        print(f"âœ… ìƒì„± ì™„ë£Œ: {output_path}")

    except ffmpeg.Error as e:
        err_msg = e.stderr.decode() if e.stderr else str(e)
        print(f"âŒ ffmpeg ì—ëŸ¬ ë°œìƒ:\n{err_msg}")
        raise RuntimeError(f"ffmpeg error: {err_msg}")

@app.get("/")
def hello():
    logger.info("ğŸ‘‹ INFO ë¡œê·¸ ì‘ë™!")
    logger.debug("ğŸ› DEBUG ë¡œê·¸ ì‘ë™!")
    return {"message": "hello"}


# @app.exception_handler(Exception)
# async def general_exception_handler(request, exc):
#    logger.error(f"ì˜ˆì™¸ ë°œìƒ: {traceback.format_exc()}")
#    return JSONResponse(status_code=500, content={"message": "Internal server error."})
def create_text_image(
        text,
        font_path,
        font_size,
        color,
        size,
        key_term=None,
        align='center',
        spacing=1,
        line_spacing=5
):
    img = Image.new("RGBA", size, (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)
    font = ImageFont.truetype(font_path, font_size)

    # í‚¤ì›Œë“œ ê°•ì¡° ë¦¬ìŠ¤íŠ¸
    highlight_terms = list(dict.fromkeys(key_term.split(','))) if key_term else []

    lines = text.split('\n')
    y_offset = 0
    space_width = draw.textlength(" ", font=font)  # ê³µë°± í•œ ê¸€ì ë„ˆë¹„

    for line in lines:
        words = line.split(' ')
        # ì´ ë„ˆë¹„ ê³„ì‚°
        total_width = 0
        for wi, word in enumerate(words):
            for ch in word:
                total_width += draw.textlength(ch, font=font) + spacing
            if wi < len(words) - 1:
                total_width += space_width
        # ì •ë ¬
        if align == 'center':
            x_start = (size[0] - total_width) // 2
        elif align == 'right':
            x_start = size[0] - total_width
        else:
            x_start = 0

        # ë‹¨ì–´ ì¶œë ¥
        for wi, word in enumerate(words):
            for idx, char in enumerate(word):
                is_highlight = False
                for term in highlight_terms:
                    tstart = word.find(term)
                    tend = tstart + len(term)
                    if tstart != -1 and tstart <= idx < tend:
                        draw.text((x_start, y_offset), char, font=font, fill="blue")
                        is_highlight = True
                        break
                if not is_highlight:
                    draw.text((x_start, y_offset), char, font=font, fill=color)
                x_start += draw.textlength(char, font=font) + spacing
            if wi < len(words) - 1:
                x_start += space_width  # ë‹¨ì–´ ì‚¬ì´ ê³µë°± ì¶”ê°€
        y_offset += font.getbbox("A")[3] - font.getbbox("A")[1] + line_spacing
    return img

def make_quiz_video_with_title_top_moviepy(data_, output_path):
    try:
        font_path = os.path.abspath('tmp/NanumMyeongjo-YetHangul.ttf')

        # ê²½ë¡œ
        question_audio = os.path.abspath(data_["question_audio"])
        answer_audio = os.path.abspath(data_["answer_audio"])
        explanation_audio = os.path.abspath(data_["explanation_audio"])
        beef_audio = os.path.abspath(data_["beef_audio"])
        bgimage_path = os.path.abspath(data_["background_image"])
        image_path = os.path.abspath(data_["image_"])

        # í…ìŠ¤íŠ¸
        question_text = data_["question_text"]
        hint_text = data_["hint_text"]
        answer_text = data_["answer_text"]
        explanation_text = data_["explanation"]
        key_term_text = data_["key_term"] + "," + answer_text

        # ì˜¤ë””ì˜¤
        question_a = AudioFileClip(question_audio)
        answer_a = AudioFileClip(answer_audio).with_start(question_a.duration + 1 + 5)
        beef_a = AudioFileClip(beef_audio).with_start(question_a.duration + 1)
        explanation_a = AudioFileClip(explanation_audio).with_start(
            question_a.duration + 1 + 5 + answer_a.duration + 1
        )
        final_audio = CompositeAudioClip([question_a, answer_a, beef_a, explanation_a]).with_fps(44100)

        # ë°°ê²½
        base_clip = ImageClip(bgimage_path).with_duration(final_audio.duration)
        text_clips = []

        # ======== ì œëª© ========
        img_title = create_text_image("í•œêµ­ì‚¬ í€´ì¦ˆ", font_path, 38, "black", (540, 100),
                                      None, align='center', spacing=1)
        title_clip = ImageClip(np.array(img_title)).with_position(("center", 12)).with_duration(final_audio.duration)
        text_clips.append(title_clip)

        # ======== ë¬¸ì œ ========
        img_question = create_text_image(wrap_text(question_text), font_path, 30, "black", (900, 300),
                                         key_term=key_term_text, align='left', spacing=0, line_spacing=15)
        question_clip = ImageClip(np.array(img_question)).with_position((190, 115)).with_duration(final_audio.duration)
        text_clips.append(question_clip)

        # ======== ì¶”ê°€ ì´ë¯¸ì§€ (ë¬¸ì œ ì•„ë˜) ========
        extra_img_clip = (
            ImageClip(image_path)
                .resized(width=360)  # âœ… ì •í™•í•œ ë©”ì„œë“œ ì´ë¦„
                .with_position((580, 150))
                .with_duration(final_audio.duration)
                .with_opacity(0.5)
                .with_effects([
                CrossFadeIn(3),  # 0.5ì´ˆ í˜ì´ë“œì¸
            ])
        )

        text_clips.append(extra_img_clip)

        # ======== íŒíŠ¸ ========
        img_hint = create_text_image(f"íŒíŠ¸: {hint_text}", font_path, 30, "blue", (500, 150),
                                     None, align='left')
        hint_clip = ImageClip(np.array(img_hint)).with_position((300, 250)) \
            .with_start(question_a.duration + 4).with_duration(2)
        text_clips.append(hint_clip)

        # ======== ì¹´ìš´íŠ¸ë‹¤ìš´ ========
        for i in range(5, 0, -1):
            img_count = create_text_image(str(i), font_path, 80, "red", (500, 200),
                                          None, align='center')
            countdown_clip = ImageClip(np.array(img_count)).with_position("center") \
                .with_start(question_a.duration + 1 + (5 - i)).with_duration(1)
            text_clips.append(countdown_clip)

        # ======== ì •ë‹µ ========
        img_answer = create_text_image(f"ì •ë‹µ: {answer_text}", font_path, 30, "black", (500, 150),
                                       None, align='left')
        answer_clip = ImageClip(np.array(img_answer)).with_position((300, 350)) \
            .with_start(question_a.duration + 1 + 5) \
            .with_duration(final_audio.duration - (question_a.duration + 1 + 5))
        text_clips.append(answer_clip)

        # ======== í•´ì„¤ ========
        img_expl = create_text_image(wrap_text(explanation_text), font_path, 28, "black", (900, 300),
                                     key_term=key_term_text, align='left', spacing=0, line_spacing=15)
        explanation_clip = ImageClip(np.array(img_expl)).with_position((200, 510)) \
            .with_start(question_a.duration + 1 + 5 + answer_a.duration + 1) \
            .with_duration(explanation_a.duration)
        text_clips.append(explanation_clip)

        # ======== í•©ì„± ë° ì¶œë ¥ ========
        final_clip = CompositeVideoClip([base_clip] + text_clips).with_audio(final_audio)
        output_path = os.path.abspath(output_path)
        final_clip.write_videofile(output_path, fps=25, codec='libx264', audio_codec='aac')

        print(f"âœ… ìƒì„± ì™„ë£Œ (moviepy): {output_path}")

        # ======== ì„ì‹œíŒŒì¼ ì‚­ì œ ========
        for del_file in [question_audio, answer_audio, explanation_audio, bgimage_path, image_path]:
            file_path = Path(del_file)
            if file_path.exists():
                file_path.unlink()
                print(f"ğŸ—‘ï¸ íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {file_path}")
            else:
                print(f"âš ï¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")

        return {"status": "ok", "output": output_path}

    except Exception as e:
        logger.error("âŒ [MoviePy/FFmpeg] ì—ëŸ¬ íƒ€ì…: %s", type(e))
        logger.error("âŒ [MoviePy/FFmpeg] ì—ëŸ¬ ë©”ì‹œì§€: %s", str(e))
        logger.error("âŒ [MoviePy/FFmpeg] ì „ì²´ ìŠ¤íƒ:\n%s", traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"ğŸ¥ moviepy/ffmpeg ì—ëŸ¬: {str(e)}")

def make_quiz_video_with_title_top(data_, output_path):
    # ğŸ”¥ ëª¨ë“  ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
    font = os.path.abspath('tmp/NanumMyeongjo-YetHangul.ttf')

    question_audio = os.path.abspath(data_["question_audio"])
    answer_audio = os.path.abspath(data_["answer_audio"])
    explanation_audio = os.path.abspath(data_["explanation_audio"])
    beef_audio = os.path.abspath(data_["beef_audio"])
    bgimage_path = os.path.abspath(data_["background_image"])
    image_path = os.path.abspath(data_["image_"])

    output_path = os.path.abspath(output_path)

    question_text = data_["question_text"]
    hint_text = data_["hint_text"]
    answer_text = data_["answer_text"]
    explanation_text = data_["explanation"]
    key_term = data_["key_term"]
    ID = data_["ID"]

    # ì˜¤ë””ì˜¤ ê¸¸ì´ ì •ë³´
    q_length = MP3(question_audio).info.length
    a_length = MP3(answer_audio).info.length
    e_length = MP3(explanation_audio).info.length

    # ì˜¤ë””ì˜¤ í´ë¦½ ë¡œë”© ë° ì‹œì‘ ì‹œê°„ ì„¤ì •
    question_a = AudioFileClip(question_audio)
    answer_a = AudioFileClip(answer_audio).with_start(question_a.duration + 1 + 5)
    beef_a = AudioFileClip(beef_audio).with_start(question_a.duration + 1)
    explanation_a = AudioFileClip(explanation_audio).with_start(
        question_a.duration + 1 + 5 + answer_a.duration + 1
    )

    final_audio = CompositeAudioClip([question_a, answer_a, beef_a, explanation_a]).with_fps(44100)
    output_audio_path = os.path.abspath(os.path.join("tmp", f"final_{ID}.mp3"))
    final_audio.write_audiofile(output_audio_path)

    try:
        image_input = ffmpeg.input(bgimage_path, loop=1, framerate=25)
        audio_input = ffmpeg.input(output_audio_path)
        base = image_input.filter('scale', 1080, 720)

        # drawtext ì¶”ê°€
        video = base.drawtext(
            text='í•œêµ­ì‚¬ í€´ì¦ˆ',
            fontfile=font,
            fontsize=33,
            fontcolor='black',
            x='(w-text_w)/2',
            y='16',
            box=1,
            boxcolor='black@0.0',
            boxborderw=10,
            enable='gte(t,0)'
        )

        video = video.drawtext(
            text=wrap_text(question_text),
            fontfile=font,
            fontsize=30,
            fontcolor='black',
            x='200',
            y='120',
            box=1,
            boxcolor='black@0.0',
            boxborderw=10,
            enable='gte(t,0)'
        )

        video = video.drawtext(
            text=f"íŒíŠ¸: {hint_text}",
            fontfile=font,
            fontsize=30,
            fontcolor='blue',
            x='(w-text_w)/2',
            y='250',
            box=1,
            boxcolor='black@0.01',
            boxborderw=10,
            enable=f'between(t,{question_a.duration + 4},{question_a.duration + 1 + 5})'
        )

        for i in range(5, 0, -1):
            start = question_a.duration + 1 + (5 - i)
            end = start + 1
            video = video.drawtext(
                text=str(i),
                fontfile=font,
                fontsize=80,
                fontcolor='red',
                x='(w-text_w)/2',
                y='(h-text_h)/2',
                box=1,
                boxcolor='black@0.0',
                boxborderw=20,
                enable=f'between(t,{start},{end})'
            )

        video = video.drawtext(
            text=f"ì •ë‹µ: {answer_text}",
            fontfile=font,
            fontsize=30,
            fontcolor='black',
            x='(w-text_w)/2',
            y='250',
            box=1,
            boxcolor='black@0.0',
            boxborderw=10,
            enable=f'gte(t,{question_a.duration + 1 + 5})'
        )

        video = video.drawtext(
            text=wrap_text(explanation_text),
            fontfile=font,
            fontsize=30,
            fontcolor='black',
            x='150',
            y='320',
            box=1,
            boxcolor='black@0.0',
            boxborderw=10,
            enable=f'gte(t,{question_a.duration + 1 + 5 + answer_a.duration + 1})'
        )

        (
            ffmpeg
            .output(
                video,
                audio_input,
                output_path,
                vcodec='libx264',
                acodec='aac',
                audio_bitrate='192k',
                pix_fmt='yuv420p',
                shortest=None,
                movflags='+faststart'
            )
            .run(
                overwrite_output=True,
                capture_stdout=True,
                capture_stderr=True
            )
        )
        print(f"âœ… ìƒì„± ì™„ë£Œ: {output_path}")

    except ffmpeg.Error as e:
        # raw bytes ì¶œë ¥
        logger.error(f"[STDERR RAW] {e.stderr}")
        # ë””ì½”ë“œ í›„ ì¶œë ¥
        logger.error(f"[STDERR DECODED]\n{e.stderr.decode(errors='ignore')}")
        raise HTTPException(status_code=500, detail=f"ffmpeg ì—ëŸ¬: {e.stderr.decode(errors='ignore')}")


@app.post("/generate-video")
async def generate_one(item: QuestionItem):
    logger.debug(f"ì§ˆë¬¸: {item.question}")
    logger.debug(f"ì •ë‹µ: {item.answer}")

    # ğŸ”½ ê° URLì— ëŒ€í•´ ê³ ìœ  ID ê¸°ë°˜ íŒŒì¼ëª… ìƒì„±
    image_id = extract_drive_id(item.image_url)
    question_audio_id = extract_drive_id(item.question_url)
    answer_audio_id = extract_drive_id(item.answer_url)
    explanation_audio_id = extract_drive_id(item.explanation_url)
    background_id = extract_drive_id(item.background_url)

    # ğŸ”½ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    image_file = download_file(item.image_url, f"image_{image_id}.png")
    question_file = download_file(item.question_url, f"question_{question_audio_id}.mp3")
    answer_file = download_file(item.answer_url, f"answer_{answer_audio_id}.mp3")
    explanation_file = download_file(item.explanation_url, f"explanation_{explanation_audio_id}.mp3")
    background_image_file = download_file(item.background_url, f"background_{background_id}.png")

    # ğŸ”½ ì¶œë ¥ íŒŒì¼ëª…
    output_filename = f"video_{question_audio_id}.mp4"
    output_file = f"tmp/{output_filename}"

    data_ = {
        "question_audio": question_file,
        "answer_audio": answer_file,
        "explanation_audio": explanation_file,
        "beef_audio": "tmp/countdown_beep.mp3",
        "image_": image_file,
        "background_image": background_image_file,
        "question_text": item.question,
        "hint_text": item.hint,
        "key_term": item.key_term,
        "answer_text": item.answer,
        "explanation": item.explanation,
        "ID": question_audio_id
    }

    result = make_quiz_video_with_title_top_moviepy(data_, output_file)
    if isinstance(result, dict) and result.get("status") == "error":
        return result  # ffmpeg ì—ëŸ¬ ë‚´ìš©ì„ ê·¸ëŒ€ë¡œ í´ë¼ì´ì–¸íŠ¸ì— ë°˜í™˜

    # create_video(data_, (output_file))

    BASE_URL = "https://primary-production-8af2.up.railway.app"
    public_video_url = f"{BASE_URL}/static/{output_filename}"

    return {
        "status": "ok",
        "ID": question_audio_id,
        "question_audio": question_file,
        "answer_audio": answer_file,
        "explanation_audio": explanation_file,
        "beef_audio": "tmp/countdown_beep.mp3",
        "image_": image_file,
        "background_image": background_image_file,
        "question_text": item.question,
        "hint_text": item.hint,
        "key_term": item.key_term,
        "answer_text": item.answer,
        "explanation": item.explanation,
        "video_output_fn": output_filename,
        "video_file_exists": Path(output_file).exists(),
        "Image": Path(background_image_file).exists(),
        "MP3": Path(question_file).exists(),
        "beef_mp3": Path("tmp/countdown_beep.mp3").exists()
    }



@app.post("/delete_file")
def delete_file(data: FileRequest):
    deleted = []
    not_found = []
    errors = []

    try:
        file_path = os.path.join('tmp', data.filename)
        deleted.append(file_path)

        # íŒŒì¼ ì‚­ì œ
        for del_file in deleted:
            path_obj = Path(del_file)
            if path_obj.exists():
                try:
                    path_obj.unlink()
                    logger.info(f"âœ… íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {path_obj}")
                except Exception as e:
                    err_msg = f"âŒ íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {path_obj}, {e}"
                    logger.error(err_msg)   # ğŸš€ Railway ì½˜ì†”ì—ë„ ì°í˜
                    errors.append({"file": str(path_obj), "error": str(e)})
            else:
                not_found.append(str(path_obj))
                logger.warning(f"âš  íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {path_obj}")

    except Exception as e:
        # ìµœìƒìœ„ ì˜ˆì™¸ ì²˜ë¦¬
        err_msg = f"âŒ delete_file í•¸ë“¤ëŸ¬ ë‚´ë¶€ ì˜¤ë¥˜: {e}"
        logger.error(err_msg)
        errors.append({"file": data.filename, "error": str(e)})

    return {
        "deleted": deleted,
        "not_found": not_found,
        "errors": errors
    }

class FileDeleteRequest(BaseModel):
    filenames: List[str]


@app.post("/delete_files")
def delete_files(request: FileDeleteRequest):
    FOLDER_PATH = "tmp"
    deleted = []
    not_found = []
    errors = []

    for fname in request.filenames:
        file_path = os.path.join(FOLDER_PATH, fname)
        deleted.append(file_path)

    # Delete tmp folder
    for del_file in deleted:
        file_path = Path(del_file)
        if file_path.exists():
            file_path.unlink()
            print(f"âœ… íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {file_path}")
        else:
            not_found=f"{file_path}ì´ ì—†ìŠµë‹ˆë‹¤."
            print(f"âš  íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")

    return {
        "deleted": deleted,
        "not_found": not_found,
        "errors": errors
    }


@app.get("/get-media")
def get_media(filename: str):
    file_path = f"{filename}"

    if not os.path.isfile(file_path):
        raise HTTPException(status_code=404, detail="íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    # íŒŒì¼ MIME íƒ€ì… ìë™ ì¶”ë¡  (jpg, png, mp4 ë“± ì§€ì›)
    mime_type, _ = mimetypes.guess_type(file_path)
    if mime_type is None:
        mime_type = "application/octet-stream"  # fallback

    return FileResponse(path=file_path, media_type=mime_type, filename=filename)


@app.post("/check-audio")
def check_audio_post(data: FileRequest):
    filename = data.filename
    file_path = Path(f"{filename}")
    if file_path.exists():
        return FileResponse(
            path=str(file_path),
            media_type="audio/mpeg",
            filename=filename
        )
    else:
        return {"error": f"{filename} not found"}


@app.get("/check-file")
def check_file(filename: str = Query(..., description="íŒŒì¼ ì´ë¦„")):
    file_path = Path(f"{filename}")

    if file_path.exists():
        # í™•ì¥ì ê¸°ë°˜ MIME íƒ€ì… ì¶”ì •
        media_type, _ = mimetypes.guess_type(str(file_path))
        if media_type is None:
            media_type = 'application/octet-stream'  # ê¸°ë³¸ê°’

        return FileResponse(
            path=str(file_path),
            media_type=media_type,
            filename=filename
        )
    else:
        return {"error": f"{filename} not found"}

@app.post("/check-video")
def check_video(filename: str):
    video_path = Path(f"{filename}")
    if video_path.exists():
        return FileResponse(
            path=str(video_path),
            media_type="video/mp4",
            filename=filename
        )
    else:
        return {"error": f"{filename} not found"}

@app.on_event("startup")
async def on_startup():
    check_ffmpeg_installed()
    print(moviepy.__version__)
    logger.info("âœ… FFmpeg ì„¤ì¹˜ í™•ì¸ë¨, ì„œë²„ ì‹œì‘!")
    check_ffmpeg_drawtext()

"""
if __name__ == "__main__":
    question_file = download_file_tmp2("https://drive.google.com/file/d/10dM1fc_hSJa9Y4-9vaSxRSjh2I0Twgs8/view?usp=drive_link", "question.mp3")
    answer_file = download_file_tmp2("https://drive.google.com/file/d/1ONaATr2Z5dbD2VlOeDG4TbOsjOOyjPrc/view?usp=drive_link", "answer.mp3")
    explanation_file = download_file_tmp2("https://drive.google.com/file/d/19df-6d0SGO5K6i2jIzmaDy-_xmB6lm2B/view?usp=drive_link", "explanation.mp3")
    background_file = download_file_tmp2("https://drive.google.com/file/d/1vjc4FlwhjfiT6Vcb2EE1Jg0FrE3ZcFFR/view?usp=drive_link", "background.png")
    image_file = download_file_tmp2("https://drive.google.com/file/d/1EXR7malg374i7SW_GfxPVXDZhQ1gkkt2/view?usp=drive_link", "image.png")

    test_data = {
        "question_audio": "tmp2/question.mp3",
        "answer_audio": "tmp2/answer.mp3",
        "explanation_audio": "tmp2/explanation.mp3",
        "beef_audio": "tmp2/countdown_beep.mp3",
        "background_image": "tmp2/background.png",
        "image_": "tmp2/image.png",
        "question_text": "ì„¸ì¢…ëŒ€ì™•ì´ ë§Œë“  ë¬¸ìëŠ”?",
        "hint_text": "ã…ã„±",
        "answer_text": "í•œê¸€",
        "explanation": "ì„¸ì¢…ëŒ€ì™•ì€ í›ˆë¯¼ì •ìŒì„ ì°½ì œí•˜ì—¬ ë°±ì„±ì´ ì‰½ê²Œ ë°°ìš°ë„ë¡ í–ˆë‹¤.",
        "key_term": "í›ˆë¯¼ì •ìŒ"
    }

    output_path = "tmp2/test_output.mp4"
    make_quiz_video_with_title_top(test_data, output_path)

    print("âœ… í…ŒìŠ¤íŠ¸ ì˜ìƒ ìƒì„± ì™„ë£Œ:", output_path)

    logger.info("Starting ...")
    uvicorn.run("main:app", host="0.0.0.0", port=8080, log_level="info")
"""

if __name__ == "__main__":
    logger.info("Starting ...")
    # í€´ì¦ˆ ì˜ìƒ ë³‘í•© í…ŒìŠ¤íŠ¸ìš© Google Drive URL ëª©ë¡
    """
    urls = [
        "https://drive.google.com/file/d/1HqCiVP0_zLEQjWfqVY7gBJZgJQfHuh6C/view?usp=drive_link",
        "https://drive.google.com/file/d/1YqErlJEnU-2c6532tIRQR_VrIzoacxJj/view?usp=drive_link",
        "https://drive.google.com/file/d/1nV5qi9XOa7R7UnCEyF3RLySPV-qwGR1G/view?usp=drive_link",
        "https://drive.google.com/file/d/1pjPGZ6DbNODsmV7plflqGrs_dm8x3rvj/view?usp=drive_link",
        "https://drive.google.com/file/d/1vP_W6K1t4swnaAeYmMfT9zZqjScSVMSh/view?usp=drive_link"
    ]


    file_paths = []
    for i, url in enumerate(urls):
        filename = f"local_merge_{i}.mp4"
        try:
            print(url)
            path = download_mp4(url, filename)
            file_paths.append(path)
        except Exception as e:
            print(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {url}, ì—ëŸ¬: {e}")

    # ë³‘í•© í…ŒìŠ¤íŠ¸
    try:
        merged_path = merge_videos_ffmpeg(file_paths, "local_test_merged")
        print("âœ… ë³‘í•© ì™„ë£Œ:", merged_path)
    except Exception as e:
        print("âŒ ë³‘í•© ì‹¤íŒ¨:", e)
    """
    # FastAPI ì‹¤í–‰
    uvicorn.run("main:app", host="0.0.0.0", port=8080, log_level="info")

