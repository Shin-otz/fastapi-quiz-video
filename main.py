import subprocess
from fastapi import FastAPI, HTTPException, Query
from fastapi.responses import FileResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
import uvicorn
import ffmpeg
import requests
from pathlib import Path
import re
import uuid
import mimetypes
import os
import logging
from mutagen.mp3 import MP3
from typing import List
import subprocess
import shutil
import time
import traceback
from moviepy import AudioFileClip, CompositeAudioClip, ImageClip, TextClip, CompositeVideoClip
import moviepy
import numpy as np
from PIL import Image, ImageDraw, ImageFont
from moviepy.video.fx.FadeIn import FadeIn
from moviepy.video.fx.FadeOut import FadeOut
from moviepy.video.fx.CrossFadeIn import CrossFadeIn
import sys

# uvicornê³¼ ê°™ì€ í•¸ë“¤ëŸ¬ ì‚¬ìš©
logging.basicConfig(
    level=logging.DEBUG,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    stream=sys.stdout  # <- ê¼­ stdoutìœ¼ë¡œ ì§€ì •
)

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

app = FastAPI()

logger.debug("HAHa ...")
logger.debug(subprocess.check_output(["ffmpeg", "-version"]).decode())
# tmp í´ë” ìƒì„±
Path("tmp").mkdir(parents=True, exist_ok=True)

app = FastAPI()
app.mount("/static", StaticFiles(directory="tmp"), name="static")

def check_ffmpeg_drawtext():
    try:
        # ffmpeg í•„í„° ëª©ë¡ì—ì„œ drawtextê°€ ìˆëŠ”ì§€ í™•ì¸
        result = subprocess.run(
            ["ffmpeg", "-filters"],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        filters_output = result.stdout

        if "drawtext" in filters_output:
            logger.info("âœ… ffmpeg drawtext í•„í„° ì§€ì› í™•ì¸ë¨.")
        else:
            logger.error("âŒ ffmpeg drawtext í•„í„°ê°€ ì—†ìŠµë‹ˆë‹¤! Dockerfileì„ ìˆ˜ì •í•˜ê±°ë‚˜ ë¹Œë“œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    except FileNotFoundError:
        logger.error("âŒ ffmpeg ëª…ë ¹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ffmpegê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    except Exception as e:
        logger.exception(f"âŒ ffmpeg í•„í„° í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


def draw_text_with_spacing(text, font_path, font_size, color, size, spacing=2, align='left'):
    """
    spacing: ê¸€ì ì‚¬ì´ ì¶”ê°€ ê°„ê²©(px)
    """
    img = Image.new("RGBA", size, (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)
    font = ImageFont.truetype(font_path, font_size)

    lines = text.split('\n')
    y_offset = 0

    for line in lines:
        # ê°€ë¡œ ìœ„ì¹˜ ê³„ì‚°
        if align == 'center':
            total_width = sum([font.getbbox(ch)[2] for ch in line]) + spacing * (len(line) - 1)
            x_start = (size[0] - total_width) // 2
        elif align == 'right':
            total_width = sum([font.getbbox(ch)[2] for ch in line]) + spacing * (len(line) - 1)
            x_start = size[0] - total_width
        else:  # left
            x_start = 0

        x = x_start
        for ch in line:
            draw.text((x, y_offset), ch, font=font, fill=color)
            ch_width = font.getbbox(ch)[2]
            x += ch_width + spacing  # ê° ê¸€ì í›„ì— spacing ì¶”ê°€
        # ë‹¤ìŒ ì¤„ y ì˜¤í”„ì…‹
        y_offset += font.getbbox("A")[3]

    return img


def wrap_text(text, max_chars=28):
    """
    ì…ë ¥ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ê°•ì œë¡œ ì¤„ë°”ê¿ˆ(\n) ì¶”ê°€
    ê¸°ë³¸ê°’: 18ê¸€ì ë„˜ìœ¼ë©´ ì¤„ë°”ê¿ˆ (ëŒ€ëµ ê°€ë¡œ 30%)
    """
    words = text.strip().split()
    lines = []
    current = ""

    for word in words:
        if len(current + " " + word) <= max_chars:
            current += " " + word if current else word
        else:
            lines.append(current)
            current = word
    if current:
        lines.append(current)

    return '\n'.join(lines)


class QuestionItem(BaseModel):
    question_type: str
    topic: str
    key_term: str
    question: str
    hint: str
    answer: str
    explanation: str
    background_url: str
    image_url: str
    question_url: str
    answer_url: str
    explanation_url: str


class FileRequest(BaseModel):
    filename: str


def check_ffmpeg_installed():
    try:
        result = subprocess.run(
            ["ffmpeg", "-version"],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            check=True
        )
        logger.info("âœ… FFmpeg ì„¤ì¹˜  í™•ì¸ë¨.")
    except FileNotFoundError:
        logger.error("âŒ FFmpegê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        raise RuntimeError("FFmpegê°€ ì‹œìŠ¤í…œì— ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. apt ë˜ëŠ” brewë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
    except subprocess.CalledProcessError as e:
        logger.error("âŒ FFmpeg ì‹¤í–‰ ì‹¤íŒ¨:")
        logger.error(e.stderr.decode())
        raise RuntimeError("FFmpegê°€ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")


def extract_drive_id(url: str) -> str:
    match = re.search(r"/d/([a-zA-Z0-9_-]+)", url)
    if match:
        return match.group(1)
    return str(uuid.uuid4())[:8]


def convert_drive_url(url: str) -> str:
    match = re.search(r"/d/([a-zA-Z0-9_-]+)", url)
    if not match:
        raise ValueError("ì˜¬ë°”ë¥¸ Google Drive ë§í¬ê°€ ì•„ë‹™ë‹ˆë‹¤.")
    file_id = match.group(1)
    return f"https://drive.google.com/uc?export=download&id={file_id}"


def download_file(url: str, filename: str) -> str:
    if "drive.google.com" in url:
        url = convert_drive_url(url)

    r = requests.get(url)
    r.raise_for_status()

    path = Path(f"tmp/{filename}")
    path.parent.mkdir(parents=True, exist_ok=True)
    if not path.exists():
        with open(path, "wb") as f:
            f.write(r.content)
    return str(path)


def download_file_tmp2(url: str, filename: str) -> str:
    if "drive.google.com" in url:
        url = convert_drive_url(url)

    r = requests.get(url)
    r.raise_for_status()

    path = Path(f"tmp2/{filename}")
    path.parent.mkdir(parents=True, exist_ok=True)
    if not path.exists():
        with open(path, "wb") as f:
            f.write(r.content)
    return str(path)


@app.get("/check-list")
def check_list(filename: str):
    file_path = Path(f"tmp/{filename}_list.txt")
    if file_path.exists():
        return FileResponse(path=str(file_path), media_type="text/plain")
    else:
        return {"error": "list.txt íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ"}


def download_drive_file(url: str, dest: Path) -> str:
    # URLì—ì„œ ID ì¶”ì¶œ
    file_id = url.split("/d/")[1].split("/")[0]
    direct_url = f"https://drive.google.com/uc?export=download&id={file_id}"
    r = requests.get(direct_url)
    dest.write_bytes(r.content)
    return str(dest)


def drive_url_to_direct_link(url: str) -> str:
    # ì˜ˆ: https://drive.google.com/file/d/1abcDEF/view?usp=sharing
    match = re.search(r"/d/([a-zA-Z0-9_-]+)", url)
    if not match:
        raise ValueError("Invalid Google Drive URL")
    file_id = match.group(1)
    return f"https://drive.google.com/uc?export=download&id={file_id}"


class VideoMergeRequest(BaseModel):
    sheet_name: str
    merged_video_name: str
    videos: List[str]  # âœ… ì¤‘ìš”: ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ì˜


def download_mp4(url: str, filename: str) -> str:
    direct_url = drive_url_to_direct_link(url)
    TMP_DIR = Path("tmp")
    path = TMP_DIR / filename
    with requests.get(direct_url, stream=True) as r:
        r.raise_for_status()
        with open(path, "wb") as f:
            for chunk in r.iter_content(chunk_size=8192):
                f.write(chunk)
    while True:
        if os.path.exists(path) and os.path.getsize(path) > 1000:
            break
    time.sleep(0.5)
    return str(path)

def merge_videos_with_fade(file_paths: list[str], output_name: str, fade_duration: float = 1.0) -> str:
    TMP_DIR = Path("tmp")
    TMP_DIR.mkdir(exist_ok=True)

    # ì²« ë²ˆì§¸ íŒŒì¼ì„ ê¸°ì¤€ìœ¼ë¡œ ì‹œì‘
    output_path = TMP_DIR / f"{output_name}.mp4"

    if len(file_paths) < 2:
        raise ValueError("ìµœì†Œ ë‘ ê°œ ì´ìƒì˜ ì˜ìƒì´ í•„ìš”í•©ë‹ˆë‹¤.")

    # ìˆœì°¨ì ìœ¼ë¡œ xfadeë¡œ í•©ì¹˜ê¸°
    current = file_paths[0]
    for idx, next_video in enumerate(file_paths[1:], start=1):
        tmp_out = TMP_DIR / f"{output_name}_step{idx}.mp4"

        # xfadeëŠ” ë‘ê°œì˜ ì…ë ¥ë§Œ ë°›ìœ¼ë¯€ë¡œ, ë°˜ë³µì ìœ¼ë¡œ ì´ì–´ ë¶™ì„
        # fade_durationë§Œí¼ êµì°¨ ì „í™˜
        command = [
            "ffmpeg",
            "-y",
            "-i", current,
            "-i", next_video,
            "-filter_complex",
            f"[0:v][1:v]xfade=transition=fade:duration={fade_duration}:offset=0[v];"
            f"[0:a][1:a]acrossfade=d={fade_duration}[a]",
            "-map", "[v]",
            "-map", "[a]",
            "-c:v", "libx264",
            "-crf", "18",
            "-preset", "veryfast",
            "-c:a", "aac",
            "-b:a", "192k",
            str(tmp_out)
        ]
        subprocess.run(command, check=True)

        # ë‹¤ìŒ ë‹¨ê³„ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©
        current = str(tmp_out)

    # ìµœì¢… ê²°ê³¼ë¬¼
    final_output = TMP_DIR / f"{output_name}_final.mp4"
    Path(current).rename(final_output)
    return str(final_output)

def get_duration(path: str) -> float:
    info = ffmpeg.probe(path)
    return float(info['format']['duration'])

def merge_videos_ffmpeg2(file_paths: list[str], output_name: str, fade_duration: float = 1.0) -> str:
    TMP_DIR = Path("tmp")
    TMP_DIR.mkdir(exist_ok=True)

    # ê²½ë¡œë¥¼ / í˜•ì‹ìœ¼ë¡œ
    file_paths = [str(Path(p).resolve().as_posix()) for p in file_paths]

    current = file_paths[0]
    for idx, next_file in enumerate(file_paths[1:], start=1):
        tmp_out = TMP_DIR / f"{output_name}_step{idx}.mp4"
        tmp_out = tmp_out.resolve().as_posix()

        dur = get_duration(current)
        offset = max(dur - fade_duration, 0)

        filter_complex = (
            f"[0:v][1:v]xfade=transition=fade:duration={fade_duration}:offset={offset}[v];"
            f"[0:a][1:a]acrossfade=d={fade_duration}[a]"
        )

        cmd = [
            "ffmpeg", "-y",
            "-i", current,
            "-i", next_file,
            "-filter_complex", filter_complex,
            "-map", "[v]", "-map", "[a]",
            "-c:v", "libx264", "-crf", "18", "-preset", "fast",
            "-c:a", "aac", "-b:a", "192k",
            tmp_out
        ]
        subprocess.run(cmd, check=True)
        current = tmp_out

    final_output = TMP_DIR / f"{output_name}_final.mp4"
    Path(current).rename(final_output)
    return str(final_output)

def merge_videos_ffmpeg(file_paths: list[str], output_name: str) -> str:
    TMP_DIR = Path("tmp")
    TMP_DIR.mkdir(exist_ok=True)

    list_path = TMP_DIR / f"{output_name}_list.txt"

    del_files = []

    # âœ… ì ˆëŒ€ê²½ë¡œ ì‚¬ìš©
    with open(list_path, "w", encoding="utf-8") as f:
        for file_path in file_paths:
            abs_path = Path(file_path).resolve().as_posix()
            f.write(f"file '{abs_path}'\n")
            del_files.append(abs_path) # ë‚˜ì¤‘ì— ì§€ìš°ê¸°

    file_num = str((len(del_files)+1)//2).zfill(2)

    output_file = f"{output_name}_{file_num}.mp4"
    output_path = TMP_DIR / f"{output_name}_{file_num}.mp4"

    del_files.append(list_path)  # ë‚˜ì¤‘ì— ì§€ìš°ê¸°
    """
    command = [
        "ffmpeg",
        "-f", "concat",
        "-safe", "0",
        "-y",
        "-i", str(list_path.resolve().as_posix()),  # ì ˆëŒ€ê²½ë¡œë¡œ ë°”ê¿”ì¤Œ
        "-c", "copy",
        str(output_path.resolve().as_posix())
    ]

    command = [
        "ffmpeg",
        "-f", "concat",
        "-safe", "0",
        "-y",
        "-i", str(list_path),
        "-c:v", "libx264",
        "-c:a", "aac",
        "-strict", "experimental",
        str(output_path)
    ]
    """
    command = [
        "ffmpeg",
        "-f", "concat",
        "-safe", "0",
        "-y",
        "-i", str(list_path),
        "-c", "copy",
        "-c:a", "aac",
        str(output_path.resolve().as_posix())
    ]

    subprocess.run(command, check=True)

    # Delete tmp folder
    for del_file in del_files:
        file_path = Path(del_file)
        if file_path.exists():
            file_path.unlink()
            print(f"âœ… íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {file_path}")
        else:
            print(f"âš  íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")

    return {"status": "ok", "output": output_file}

@app.post("/merge-videos")
async def merge_videos(payload: List[VideoMergeRequest]):
    results = []

    for item in payload:
        sheet = item.sheet_name
        merged_name = item.merged_video_name
        video_urls = item.videos

        print(f"[{sheet}] '{merged_name}' ë³‘í•© ì‹œì‘: {len(video_urls)}ê°œ ì˜ìƒ")

        # 1. ê° URLì—ì„œ mp4 ë‹¤ìš´ë¡œë“œ
        file_paths = []
        for i, url in enumerate(video_urls):
            filename = f"{merged_name}_{i}.mp4"
            try:
                path = download_mp4(url, filename)
                file_paths.append(path)
            except Exception as e:
                print(f"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {url}, ì—ëŸ¬: {e}")
                results.append({
                    "sheet": sheet,
                    "merged_video_name": merged_name,
                    "video_count": len(video_urls),
                    "status": "fail",
                    "error": str(e)
                })
                continue
        print("----")
        print(file_paths)

        # 2. FFmpegë¡œ ë³‘í•©
        try:
            print("----")
            print(file_paths)
            output_path = merge_videos_ffmpeg(file_paths, merged_name)
            status = "success"
        except Exception as e:
            print(f"ë³‘í•© ì‹¤íŒ¨: {e}")
            output_path = file_paths
            status = "fail"

        # 3. ê²°ê³¼ ì €ì¥
        results.append({
            "sheet": sheet,
            "merged_video_name": merged_name,
            "video_count": len(video_urls),
            "merged_path": output_path,
            "list_path": video_urls,
            "ffmpeg": shutil.which("ffmpeg"),
            "status": status
        })

    return {"result": results}


class NextItem(BaseModel):
    next_text_mp3_url: str
    next_bg_url: str


@app.post("/generate-mp4_next")
async def generate_next(item: NextItem):
    # ğŸ”½ ê° URLì— ëŒ€í•´ ê³ ìœ  ID ê¸°ë°˜ íŒŒì¼ëª… ìƒì„±
    next_audio_id = extract_drive_id(item.next_text_mp3_url)
    background_id = extract_drive_id(item.next_bg_url)

    # ğŸ”½ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    next_mp3_file = download_file(item.next_text_mp3_url, f"next_mp3_{next_audio_id}.mp3")
    background_image_file = download_file(item.next_bg_url, f"next_bg_{background_id}.png")

    # ğŸ”½ ì¶œë ¥ íŒŒì¼ëª…
    output_filename = f"next_{next_audio_id}.mp4"
    output_file = f"tmp/{output_filename}"

    data_ = {
        "next_mp3": next_mp3_file,
        "next_bg_image": background_image_file,
    }

    make_next_moviepy_mp4(data_, output_file)

    # create_video(data_, (output_file))

    BASE_URL = "https://primary-production-8af2.up.railway.app"
    public_video_url = f"{BASE_URL}/static/{output_filename}"

    return {
        "status": "ok",
        "next_mp3": next_mp3_file,
        "next_bg_image": background_image_file,
        "next_mp4": output_file
    }


def make_next_moviepy_mp4(data_, output_path):
    next_mp3_path = os.path.abspath(data_["next_mp3"])
    bgimage_path = os.path.abspath(data_["next_bg_image"])
    output_path = os.path.abspath(output_path)

    # ì˜¤ë””ì˜¤
    question_a = AudioFileClip(next_mp3_path)
    final_audio = CompositeAudioClip([question_a]).with_fps(44100)

    # ì´ë¯¸ì§€ (moviepy 2.1.2 ê¸°ì¤€ with_resize ì‚¬ìš©)

    base_clip = ImageClip(bgimage_path).with_duration(final_audio.duration)

    # í•©ì„±
    final_clip = base_clip.with_audio(final_audio)

    # ì¶œë ¥
    final_clip.write_videofile(
        output_path,
        fps=25,
        codec='libx264',
        audio_codec='aac'
    )

    print(f"âœ… ìƒì„± ì™„ë£Œ (moviepy): {output_path}")

    del_files = []
    del_files.append(next_mp3_path)
    del_files.append(bgimage_path)

    # Delete tmp folder
    for del_file in del_files:
        file_path = Path(del_file)
        if file_path.exists():
            file_path.unlink()
            print(f"âœ… íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {file_path}")
        else:
            print(f"âš  íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")

    return {"status": "ok", "output": output_path}


def make_next_mp4(data_, output_path):
    next_mp3_path = data_["next_mp3"]
    bgimage_path = data_["next_bg_image"]

    try:
        # ì´ë¯¸ì§€ ì…ë ¥ (ë°˜ë³µ), í”„ë ˆì„ë ˆì´íŠ¸ 1fps ì§€ì •
        image_input = ffmpeg.input(bgimage_path, loop=1)

        question_a = AudioFileClip(next_mp3_path)
        final_audio = CompositeAudioClip([question_a]).with_fps(44100)
        output_audio_path = os.path.join("tmp", f"next_final.mp3")
        final_audio.write_audiofile(output_audio_path)
        # ì˜¤ë””ì˜¤ ì…ë ¥
        audio_input = ffmpeg.input(output_audio_path)

        # ìŠ¤ì¼€ì¼ í•„í„° ì ìš©
        base = image_input.filter('scale', 1080, 720)

        ffmpeg.output(
            base, audio_input,
            output_path,

            vcodec='libx264',
            acodec='aac',
            audio_bitrate='192k',
            pix_fmt='yuv420p',
            shortest=None,
            movflags='+faststart'
        ).run(overwrite_output=True)

        print(f"âœ… ìƒì„± ì™„ë£Œ: {output_path}")

    except ffmpeg.Error as e:
        err_msg = e.stderr.decode() if e.stderr else str(e)
        print(f"âŒ ffmpeg ì—ëŸ¬ ë°œìƒ:\n{err_msg}")
        raise RuntimeError(f"ffmpeg error: {err_msg}")


@app.get("/")
def hello():
    logger.info("ğŸ‘‹ INFO ë¡œê·¸ ì‘ë™!")
    logger.debug("ğŸ› DEBUG ë¡œê·¸ ì‘ë™!")
    file = Path(-audio_file).exists()
    return {"message": "hello"}


# @app.exception_handler(Exception)
# async def general_exception_handler(request, exc):
#    logger.error(f"ì˜ˆì™¸ ë°œìƒ: {traceback.format_exc()}")
#    return JSONResponse(status_code=500, content={"message": "Internal server error."})
def create_text_image(
        text,
        font_path,
        font_size,
        color,
        size,
        key_term=None,
        align='center',
        spacing=1,
        line_spacing=5
):
    img = Image.new("RGBA", size, (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)
    font = ImageFont.truetype(font_path, font_size)

    # í‚¤ì›Œë“œ ê°•ì¡° ë¦¬ìŠ¤íŠ¸
    highlight_terms = list(dict.fromkeys(key_term.split(','))) if key_term else []

    lines = text.split('\n')
    y_offset = 0
    space_width = draw.textlength(" ", font=font)  # ê³µë°± í•œ ê¸€ì ë„ˆë¹„

    for line in lines:
        words = line.split(' ')
        # ì´ ë„ˆë¹„ ê³„ì‚°
        total_width = 0
        for wi, word in enumerate(words):
            for ch in word:
                total_width += draw.textlength(ch, font=font) + spacing
            if wi < len(words) - 1:
                total_width += space_width
        # ì •ë ¬
        if align == 'center':
            x_start = (size[0] - total_width) // 2
        elif align == 'right':
            x_start = size[0] - total_width
        else:
            x_start = 0

        # ë‹¨ì–´ ì¶œë ¥
        for wi, word in enumerate(words):
            for idx, char in enumerate(word):
                is_highlight = False
                for term in highlight_terms:
                    tstart = word.find(term)
                    tend = tstart + len(term)
                    if tstart != -1 and tstart <= idx < tend:
                        draw.text((x_start, y_offset), char, font=font, fill="blue")
                        is_highlight = True
                        break
                if not is_highlight:
                    draw.text((x_start, y_offset), char, font=font, fill=color)
                x_start += draw.textlength(char, font=font) + spacing
            if wi < len(words) - 1:
                x_start += space_width  # ë‹¨ì–´ ì‚¬ì´ ê³µë°± ì¶”ê°€

        y_offset += font.getbbox("A")[3] - font.getbbox("A")[1] + line_spacing

    return img

def make_quiz_video_with_title_top_moviepy(data_, output_path):
    try:
        font_path = os.path.abspath('tmp/NanumMyeongjo-YetHangul.ttf')

        # ê²½ë¡œ
        question_audio = os.path.abspath(data_["question_audio"])
        answer_audio = os.path.abspath(data_["answer_audio"])
        explanation_audio = os.path.abspath(data_["explanation_audio"])
        beef_audio = os.path.abspath(data_["beef_audio"])
        bgimage_path = os.path.abspath(data_["background_image"])
        image_path = os.path.abspath(data_["image_"])

        # í…ìŠ¤íŠ¸
        question_text = data_["question_text"]
        hint_text = data_["hint_text"]
        answer_text = data_["answer_text"]
        explanation_text = data_["explanation"]
        key_term_text = data_["key_term"] + "," + answer_text

        # ì˜¤ë””ì˜¤
        question_a = AudioFileClip(question_audio)
        answer_a = AudioFileClip(answer_audio).with_start(question_a.duration + 1 + 5)
        beef_a = AudioFileClip(beef_audio).with_start(question_a.duration + 1)
        explanation_a = AudioFileClip(explanation_audio).with_start(
            question_a.duration + 1 + 5 + answer_a.duration + 1
        )
        final_audio = CompositeAudioClip([question_a, answer_a, beef_a, explanation_a]).with_fps(44100)

        # ë°°ê²½
        base_clip = ImageClip(bgimage_path).with_duration(final_audio.duration)
        text_clips = []

        # ======== ì œëª© ========
        img_title = create_text_image("í•œêµ­ì‚¬ í€´ì¦ˆ", font_path, 38, "black", (540, 100),
                                      None, align='center', spacing=1)
        title_clip = ImageClip(np.array(img_title)).with_position(("center", 12)).with_duration(final_audio.duration)
        text_clips.append(title_clip)

        # ======== ë¬¸ì œ ========
        img_question = create_text_image(wrap_text(question_text), font_path, 30, "black", (900, 300),
                                         key_term=key_term_text, align='left', spacing=0, line_spacing=15)
        question_clip = ImageClip(np.array(img_question)).with_position((190, 115)).with_duration(final_audio.duration)
        text_clips.append(question_clip)

        # ======== ì¶”ê°€ ì´ë¯¸ì§€ (ë¬¸ì œ ì•„ë˜) ========
        extra_img_clip = (
            ImageClip(image_path)
                .resized(width=360)  # âœ… ì •í™•í•œ ë©”ì„œë“œ ì´ë¦„
                .with_position((580, 150))
                .with_duration(final_audio.duration)
                .with_opacity(0.5)
                .with_effects([
                CrossFadeIn(3),  # 0.5ì´ˆ í˜ì´ë“œì¸
            ])
        )

        text_clips.append(extra_img_clip)

        # ======== íŒíŠ¸ ========
        img_hint = create_text_image(f"íŒíŠ¸: {hint_text}", font_path, 30, "blue", (500, 150),
                                     None, align='left')
        hint_clip = ImageClip(np.array(img_hint)).with_position((300, 250)) \
            .with_start(question_a.duration + 4).with_duration(2)
        text_clips.append(hint_clip)

        # ======== ì¹´ìš´íŠ¸ë‹¤ìš´ ========
        for i in range(5, 0, -1):
            img_count = create_text_image(str(i), font_path, 80, "red", (500, 200),
                                          None, align='center')
            countdown_clip = ImageClip(np.array(img_count)).with_position("center") \
                .with_start(question_a.duration + 1 + (5 - i)).with_duration(1)
            text_clips.append(countdown_clip)

        # ======== ì •ë‹µ ========
        img_answer = create_text_image(f"ì •ë‹µ: {answer_text}", font_path, 30, "black", (500, 150),
                                       None, align='left')
        answer_clip = ImageClip(np.array(img_answer)).with_position((300, 350)) \
            .with_start(question_a.duration + 1 + 5) \
            .with_duration(final_audio.duration - (question_a.duration + 1 + 5))
        text_clips.append(answer_clip)

        # ======== í•´ì„¤ ========
        img_expl = create_text_image(wrap_text(explanation_text), font_path, 28, "black", (900, 300),
                                     key_term=key_term_text, align='left', spacing=0, line_spacing=15)
        explanation_clip = ImageClip(np.array(img_expl)).with_position((200, 510)) \
            .with_start(question_a.duration + 1 + 5 + answer_a.duration + 1) \
            .with_duration(explanation_a.duration)
        text_clips.append(explanation_clip)

        # ======== í•©ì„± ë° ì¶œë ¥ ========
        final_clip = CompositeVideoClip([base_clip] + text_clips).with_audio(final_audio)
        output_path = os.path.abspath(output_path)
        final_clip.write_videofile(output_path, fps=25, codec='libx264', audio_codec='aac')

        print(f"âœ… ìƒì„± ì™„ë£Œ (moviepy): {output_path}")

        # ======== ì„ì‹œíŒŒì¼ ì‚­ì œ ========
        for del_file in [question_audio, answer_audio, explanation_audio, bgimage_path, image_path]:
            file_path = Path(del_file)
            if file_path.exists():
                file_path.unlink()
                print(f"ğŸ—‘ï¸ íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {file_path}")
            else:
                print(f"âš ï¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")

        return {"status": "ok", "output": output_path}

    except Exception as e:
        logger.error("âŒ [MoviePy/FFmpeg] ì—ëŸ¬ íƒ€ì…: %s", type(e))
        logger.error("âŒ [MoviePy/FFmpeg] ì—ëŸ¬ ë©”ì‹œì§€: %s", str(e))
        logger.error("âŒ [MoviePy/FFmpeg] ì „ì²´ ìŠ¤íƒ:\n%s", traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"ğŸ¥ moviepy/ffmpeg ì—ëŸ¬: {str(e)}")

def make_quiz_video_with_title_top(data_, output_path):
    # ğŸ”¥ ëª¨ë“  ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
    font = os.path.abspath('tmp/NanumMyeongjo-YetHangul.ttf')

    question_audio = os.path.abspath(data_["question_audio"])
    answer_audio = os.path.abspath(data_["answer_audio"])
    explanation_audio = os.path.abspath(data_["explanation_audio"])
    beef_audio = os.path.abspath(data_["beef_audio"])
    bgimage_path = os.path.abspath(data_["background_image"])
    image_path = os.path.abspath(data_["image_"])

    output_path = os.path.abspath(output_path)

    question_text = data_["question_text"]
    hint_text = data_["hint_text"]
    answer_text = data_["answer_text"]
    explanation_text = data_["explanation"]
    key_term = data_["key_term"]
    ID = data_["ID"]

    # ì˜¤ë””ì˜¤ ê¸¸ì´ ì •ë³´
    q_length = MP3(question_audio).info.length
    a_length = MP3(answer_audio).info.length
    e_length = MP3(explanation_audio).info.length

    # ì˜¤ë””ì˜¤ í´ë¦½ ë¡œë”© ë° ì‹œì‘ ì‹œê°„ ì„¤ì •
    question_a = AudioFileClip(question_audio)
    answer_a = AudioFileClip(answer_audio).with_start(question_a.duration + 1 + 5)
    beef_a = AudioFileClip(beef_audio).with_start(question_a.duration + 1)
    explanation_a = AudioFileClip(explanation_audio).with_start(
        question_a.duration + 1 + 5 + answer_a.duration + 1
    )

    final_audio = CompositeAudioClip([question_a, answer_a, beef_a, explanation_a]).with_fps(44100)
    output_audio_path = os.path.abspath(os.path.join("tmp", f"final_{ID}.mp3"))
    final_audio.write_audiofile(output_audio_path)

    try:
        image_input = ffmpeg.input(bgimage_path, loop=1, framerate=25)
        audio_input = ffmpeg.input(output_audio_path)
        base = image_input.filter('scale', 1080, 720)

        # drawtext ì¶”ê°€
        video = base.drawtext(
            text='í•œêµ­ì‚¬ í€´ì¦ˆ',
            fontfile=font,
            fontsize=33,
            fontcolor='black',
            x='(w-text_w)/2',
            y='16',
            box=1,
            boxcolor='black@0.0',
            boxborderw=10,
            enable='gte(t,0)'
        )

        video = video.drawtext(
            text=wrap_text(question_text),
            fontfile=font,
            fontsize=30,
            fontcolor='black',
            x='200',
            y='120',
            box=1,
            boxcolor='black@0.0',
            boxborderw=10,
            enable='gte(t,0)'
        )

        video = video.drawtext(
            text=f"íŒíŠ¸: {hint_text}",
            fontfile=font,
            fontsize=30,
            fontcolor='blue',
            x='(w-text_w)/2',
            y='250',
            box=1,
            boxcolor='black@0.01',
            boxborderw=10,
            enable=f'between(t,{question_a.duration + 4},{question_a.duration + 1 + 5})'
        )

        for i in range(5, 0, -1):
            start = question_a.duration + 1 + (5 - i)
            end = start + 1
            video = video.drawtext(
                text=str(i),
                fontfile=font,
                fontsize=80,
                fontcolor='red',
                x='(w-text_w)/2',
                y='(h-text_h)/2',
                box=1,
                boxcolor='black@0.0',
                boxborderw=20,
                enable=f'between(t,{start},{end})'
            )

        video = video.drawtext(
            text=f"ì •ë‹µ: {answer_text}",
            fontfile=font,
            fontsize=30,
            fontcolor='black',
            x='(w-text_w)/2',
            y='250',
            box=1,
            boxcolor='black@0.0',
            boxborderw=10,
            enable=f'gte(t,{question_a.duration + 1 + 5})'
        )

        video = video.drawtext(
            text=wrap_text(explanation_text),
            fontfile=font,
            fontsize=30,
            fontcolor='black',
            x='150',
            y='320',
            box=1,
            boxcolor='black@0.0',
            boxborderw=10,
            enable=f'gte(t,{question_a.duration + 1 + 5 + answer_a.duration + 1})'
        )

        (
            ffmpeg
            .output(
                video,
                audio_input,
                output_path,
                vcodec='libx264',
                acodec='aac',
                audio_bitrate='192k',
                pix_fmt='yuv420p',
                shortest=None,
                movflags='+faststart'
            )
            .run(
                overwrite_output=True,
                capture_stdout=True,
                capture_stderr=True
            )
        )
        print(f"âœ… ìƒì„± ì™„ë£Œ: {output_path}")

    except ffmpeg.Error as e:
        # raw bytes ì¶œë ¥
        logger.error(f"[STDERR RAW] {e.stderr}")
        # ë””ì½”ë“œ í›„ ì¶œë ¥
        logger.error(f"[STDERR DECODED]\n{e.stderr.decode(errors='ignore')}")
        raise HTTPException(status_code=500, detail=f"ffmpeg ì—ëŸ¬: {e.stderr.decode(errors='ignore')}")


@app.post("/generate-video")
async def generate_one(item: QuestionItem):
    logger.debug(f"ì§ˆë¬¸: {item.question}")
    logger.debug(f"ì •ë‹µ: {item.answer}")

    # ğŸ”½ ê° URLì— ëŒ€í•´ ê³ ìœ  ID ê¸°ë°˜ íŒŒì¼ëª… ìƒì„±
    image_id = extract_drive_id(item.image_url)
    question_audio_id = extract_drive_id(item.question_url)
    answer_audio_id = extract_drive_id(item.answer_url)
    explanation_audio_id = extract_drive_id(item.explanation_url)
    background_id = extract_drive_id(item.background_url)

    # ğŸ”½ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    image_file = download_file(item.image_url, f"image_{image_id}.png")
    question_file = download_file(item.question_url, f"question_{question_audio_id}.mp3")
    answer_file = download_file(item.answer_url, f"answer_{answer_audio_id}.mp3")
    explanation_file = download_file(item.explanation_url, f"explanation_{explanation_audio_id}.mp3")
    background_image_file = download_file(item.background_url, f"background_{background_id}.png")

    # ğŸ”½ ì¶œë ¥ íŒŒì¼ëª…
    output_filename = f"video_{question_audio_id}.mp4"
    output_file = f"tmp/{output_filename}"

    data_ = {
        "question_audio": question_file,
        "answer_audio": answer_file,
        "explanation_audio": explanation_file,
        "beef_audio": "tmp/countdown_beep.mp3",
        "image_": image_file,
        "background_image": background_image_file,
        "question_text": item.question,
        "hint_text": item.hint,
        "key_term": item.key_term,
        "answer_text": item.answer,
        "explanation": item.explanation,
        "ID": question_audio_id
    }

    result = make_quiz_video_with_title_top_moviepy(data_, output_file)
    if isinstance(result, dict) and result.get("status") == "error":
        return result  # ffmpeg ì—ëŸ¬ ë‚´ìš©ì„ ê·¸ëŒ€ë¡œ í´ë¼ì´ì–¸íŠ¸ì— ë°˜í™˜

    # create_video(data_, (output_file))

    BASE_URL = "https://primary-production-8af2.up.railway.app"
    public_video_url = f"{BASE_URL}/static/{output_filename}"

    return {
        "status": "ok",
        "ID": question_audio_id,
        "question_audio": question_file,
        "answer_audio": answer_file,
        "explanation_audio": explanation_file,
        "beef_audio": "tmp/countdown_beep.mp3",
        "image_": image_file,
        "background_image": background_image_file,
        "question_text": item.question,
        "hint_text": item.hint,
        "key_term": item.key_term,
        "answer_text": item.answer,
        "explanation": item.explanation,
        "video_output_fn": output_filename,
        "video_file_exists": Path(output_file).exists(),
        "Image": Path(background_image_file).exists(),
        "MP3": Path(question_file).exists(),
        "beef_mp3": Path("tmp/countdown_beep.mp3").exists()
    }



@app.post("/delete_file")
def delete_file(data: FileRequest):
    deleted = []
    not_found = []
    errors = []

    try:
        file_path = os.path.join('tmp', data.filename)
        deleted.append(file_path)

        # íŒŒì¼ ì‚­ì œ
        for del_file in deleted:
            path_obj = Path(del_file)
            if path_obj.exists():
                try:
                    path_obj.unlink()
                    logger.info(f"âœ… íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {path_obj}")
                except Exception as e:
                    err_msg = f"âŒ íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {path_obj}, {e}"
                    logger.error(err_msg)   # ğŸš€ Railway ì½˜ì†”ì—ë„ ì°í˜
                    errors.append({"file": str(path_obj), "error": str(e)})
            else:
                not_found.append(str(path_obj))
                logger.warning(f"âš  íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {path_obj}")

    except Exception as e:
        # ìµœìƒìœ„ ì˜ˆì™¸ ì²˜ë¦¬
        err_msg = f"âŒ delete_file í•¸ë“¤ëŸ¬ ë‚´ë¶€ ì˜¤ë¥˜: {e}"
        logger.error(err_msg)
        errors.append({"file": data.filename, "error": str(e)})

    return {
        "deleted": deleted,
        "not_found": not_found,
        "errors": errors
    }

class FileDeleteRequest(BaseModel):
    filenames: List[str]


@app.post("/delete_files")
def delete_files(request: FileDeleteRequest):
    FOLDER_PATH = "tmp"
    deleted = []
    not_found = []
    errors = []

    for fname in request.filenames:
        file_path = os.path.join(FOLDER_PATH, fname)
        deleted.append(file_path)

    # Delete tmp folder
    for del_file in deleted:
        file_path = Path(del_file)
        if file_path.exists():
            file_path.unlink()
            print(f"âœ… íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {file_path}")
        else:
            not_found=f"{file_path}ì´ ì—†ìŠµë‹ˆë‹¤."
            print(f"âš  íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")

    return {
        "deleted": deleted,
        "not_found": not_found,
        "errors": errors
    }


@app.get("/get-media")
def get_media(filename: str):
    file_path = f"{filename}"

    if not os.path.isfile(file_path):
        raise HTTPException(status_code=404, detail="íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    # íŒŒì¼ MIME íƒ€ì… ìë™ ì¶”ë¡  (jpg, png, mp4 ë“± ì§€ì›)
    mime_type, _ = mimetypes.guess_type(file_path)
    if mime_type is None:
        mime_type = "application/octet-stream"  # fallback

    return FileResponse(path=file_path, media_type=mime_type, filename=filename)


@app.post("/check-audio")
def check_audio_post(data: FileRequest):
    filename = data.filename
    file_path = Path(f"{filename}")
    if file_path.exists():
        return FileResponse(
            path=str(file_path),
            media_type="audio/mpeg",
            filename=filename
        )
    else:
        return {"error": f"{filename} not found"}


@app.get("/check-file")
def check_file(filename: str = Query(..., description="íŒŒì¼ ì´ë¦„")):
    file_path = Path(f"{filename}")

    if file_path.exists():
        # í™•ì¥ì ê¸°ë°˜ MIME íƒ€ì… ì¶”ì •
        media_type, _ = mimetypes.guess_type(str(file_path))
        if media_type is None:
            media_type = 'application/octet-stream'  # ê¸°ë³¸ê°’

        return FileResponse(
            path=str(file_path),
            media_type=media_type,
            filename=filename
        )
    else:
        return {"error": f"{filename} not found"}

@app.post("/check-video")
def check_video(filename: str):
    video_path = Path(f"{filename}")
    if video_path.exists():
        return FileResponse(
            path=str(video_path),
            media_type="video/mp4",
            filename=filename
        )
    else:
        return {"error": f"{filename} not found"}

@app.on_event("startup")
async def on_startup():
    check_ffmpeg_installed()
    print(moviepy.__version__)
    logger.info("âœ… FFmpeg ì„¤ì¹˜ í™•ì¸ë¨, ì„œë²„ ì‹œì‘!")
    check_ffmpeg_drawtext()

"""
if __name__ == "__main__":
    question_file = download_file_tmp2("https://drive.google.com/file/d/10dM1fc_hSJa9Y4-9vaSxRSjh2I0Twgs8/view?usp=drive_link", "question.mp3")
    answer_file = download_file_tmp2("https://drive.google.com/file/d/1ONaATr2Z5dbD2VlOeDG4TbOsjOOyjPrc/view?usp=drive_link", "answer.mp3")
    explanation_file = download_file_tmp2("https://drive.google.com/file/d/19df-6d0SGO5K6i2jIzmaDy-_xmB6lm2B/view?usp=drive_link", "explanation.mp3")
    background_file = download_file_tmp2("https://drive.google.com/file/d/1vjc4FlwhjfiT6Vcb2EE1Jg0FrE3ZcFFR/view?usp=drive_link", "background.png")
    image_file = download_file_tmp2("https://drive.google.com/file/d/1EXR7malg374i7SW_GfxPVXDZhQ1gkkt2/view?usp=drive_link", "image.png")

    test_data = {
        "question_audio": "tmp2/question.mp3",
        "answer_audio": "tmp2/answer.mp3",
        "explanation_audio": "tmp2/explanation.mp3",
        "beef_audio": "tmp2/countdown_beep.mp3",
        "background_image": "tmp2/background.png",
        "image_": "tmp2/image.png",
        "question_text": "ì„¸ì¢…ëŒ€ì™•ì´ ë§Œë“  ë¬¸ìëŠ”?",
        "hint_text": "ã…ã„±",
        "answer_text": "í•œê¸€",
        "explanation": "ì„¸ì¢…ëŒ€ì™•ì€ í›ˆë¯¼ì •ìŒì„ ì°½ì œí•˜ì—¬ ë°±ì„±ì´ ì‰½ê²Œ ë°°ìš°ë„ë¡ í–ˆë‹¤.",
        "key_term": "í›ˆë¯¼ì •ìŒ"
    }

    output_path = "tmp2/test_output.mp4"
    make_quiz_video_with_title_top(test_data, output_path)

    print("âœ… í…ŒìŠ¤íŠ¸ ì˜ìƒ ìƒì„± ì™„ë£Œ:", output_path)

    logger.info("Starting ...")
    uvicorn.run("main:app", host="0.0.0.0", port=8080, log_level="info")
"""

if __name__ == "__main__":
    logger.info("Starting ...")
    # í€´ì¦ˆ ì˜ìƒ ë³‘í•© í…ŒìŠ¤íŠ¸ìš© Google Drive URL ëª©ë¡
    """
    urls = [
        "https://drive.google.com/file/d/1HqCiVP0_zLEQjWfqVY7gBJZgJQfHuh6C/view?usp=drive_link",
        "https://drive.google.com/file/d/1YqErlJEnU-2c6532tIRQR_VrIzoacxJj/view?usp=drive_link",
        "https://drive.google.com/file/d/1nV5qi9XOa7R7UnCEyF3RLySPV-qwGR1G/view?usp=drive_link",
        "https://drive.google.com/file/d/1pjPGZ6DbNODsmV7plflqGrs_dm8x3rvj/view?usp=drive_link",
        "https://drive.google.com/file/d/1vP_W6K1t4swnaAeYmMfT9zZqjScSVMSh/view?usp=drive_link"
    ]


    file_paths = []
    for i, url in enumerate(urls):
        filename = f"local_merge_{i}.mp4"
        try:
            print(url)
            path = download_mp4(url, filename)
            file_paths.append(path)
        except Exception as e:
            print(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {url}, ì—ëŸ¬: {e}")

    # ë³‘í•© í…ŒìŠ¤íŠ¸
    try:
        merged_path = merge_videos_ffmpeg(file_paths, "local_test_merged")
        print("âœ… ë³‘í•© ì™„ë£Œ:", merged_path)
    except Exception as e:
        print("âŒ ë³‘í•© ì‹¤íŒ¨:", e)
    """
    # FastAPI ì‹¤í–‰
    uvicorn.run("main:app", host="0.0.0.0", port=8080, log_level="info")

